{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "WineDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpZJmJcywvbu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iQcjMtFwvbw"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "    \n",
        "    def __init__(self):\n",
        "        data=np.loadtxt('./data/wine.csv',delimiter=\",\",dtype=np.float32,skiprows=1) #skip header\n",
        "        self.x = torch.from_numpy(data[: , 1:])\n",
        "        self.y = torch.from_numpy(data[:, 0])\n",
        "        self.y=torch.tensor(self.y,dtype=torch.int64)\n",
        "        self.n_samples = data.shape[0] \n",
        "    def __getitem__(self,idx):\n",
        "        return self.x[idx],self.y[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggJJHe5jwvbx"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self,input_dim,output_dim,lr,l1_size,l2_size):\n",
        "        \n",
        "        super(Network, self).__init__()\n",
        "        self.input_dim=input_dim\n",
        "        self.output_dim=output_dim\n",
        "        self.lr=lr\n",
        "        self.l1_size=l1_size\n",
        "        self.l2_size=l2_size\n",
        "#         self.optimizer=torch.optim.Adam(self.parameters(),lr=self.lr)\n",
        "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        self.l1=nn.Linear(input_dim,self.l1_size)\n",
        "        self.l2=nn.Linear(self.l1_size,self.l2_size)\n",
        "        self.l3=nn.Linear(self.l2_size,output_dim)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # x=x.to(self.device)\n",
        "        x=F.relu(self.l1(x))\n",
        "        x=F.relu(self.l2(x))\n",
        "        x=self.l3(x)\n",
        "        # output=torch.softmax(x,dim=1)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "        "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhFzkkjfwvbx"
      },
      "source": [
        "n=Network(13,3,0.001,8,8)\n",
        "optimizer=torch.optim.Adam(n.parameters(),lr=n.lr)\n",
        "criterion=nn.CrossEntropyLoss()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ4ijgK7wvby",
        "outputId": "10378aa0-7c59-4a43-9b64-64023689256e"
      },
      "source": [
        "dataset = WineDataset()\n",
        "train_set,test_set,val_set=torch.utils.data.random_split(dataset,[142,30,6])\n",
        "# dataloader=DataLoader(dataset=dataset, batch_size=8, shuffle=True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtMVvyRBwvby",
        "outputId": "d8b73a46-3876-4f3c-f3f9-e1ddf84960ec"
      },
      "source": [
        "train_set=DataLoader(dataset=train_set,batch_size=4,shuffle=True)\n",
        "example=iter(train_set)\n",
        "sample,label=example.next()\n",
        "print(sample.shape,label-1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 13]) tensor([2, 2, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnMJj630wvbz",
        "outputId": "4cbccde9-a4cf-47f7-8c46-1ab27e3448a9"
      },
      "source": [
        "for e in range(1000):\n",
        "    running_loss=0\n",
        "    for i,(inputs,labels) in enumerate(train_set):\n",
        "        outputs=n(inputs)\n",
        "        labels=labels-1\n",
        "        loss=criterion(outputs,labels)\n",
        "        running_loss+=loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"Epoch:\"+str(e)+\" Loss:\"+str(running_loss/len(train_set)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Loss:tensor(8.4139, grad_fn=<DivBackward0>)\n",
            "Epoch:1 Loss:tensor(1.0322, grad_fn=<DivBackward0>)\n",
            "Epoch:2 Loss:tensor(0.8745, grad_fn=<DivBackward0>)\n",
            "Epoch:3 Loss:tensor(0.8627, grad_fn=<DivBackward0>)\n",
            "Epoch:4 Loss:tensor(0.8616, grad_fn=<DivBackward0>)\n",
            "Epoch:5 Loss:tensor(0.8405, grad_fn=<DivBackward0>)\n",
            "Epoch:6 Loss:tensor(0.8369, grad_fn=<DivBackward0>)\n",
            "Epoch:7 Loss:tensor(0.8153, grad_fn=<DivBackward0>)\n",
            "Epoch:8 Loss:tensor(0.8029, grad_fn=<DivBackward0>)\n",
            "Epoch:9 Loss:tensor(0.8053, grad_fn=<DivBackward0>)\n",
            "Epoch:10 Loss:tensor(0.7949, grad_fn=<DivBackward0>)\n",
            "Epoch:11 Loss:tensor(0.7944, grad_fn=<DivBackward0>)\n",
            "Epoch:12 Loss:tensor(0.7774, grad_fn=<DivBackward0>)\n",
            "Epoch:13 Loss:tensor(0.7746, grad_fn=<DivBackward0>)\n",
            "Epoch:14 Loss:tensor(0.7715, grad_fn=<DivBackward0>)\n",
            "Epoch:15 Loss:tensor(0.7606, grad_fn=<DivBackward0>)\n",
            "Epoch:16 Loss:tensor(0.7527, grad_fn=<DivBackward0>)\n",
            "Epoch:17 Loss:tensor(0.7586, grad_fn=<DivBackward0>)\n",
            "Epoch:18 Loss:tensor(0.7527, grad_fn=<DivBackward0>)\n",
            "Epoch:19 Loss:tensor(0.7651, grad_fn=<DivBackward0>)\n",
            "Epoch:20 Loss:tensor(0.7333, grad_fn=<DivBackward0>)\n",
            "Epoch:21 Loss:tensor(0.7211, grad_fn=<DivBackward0>)\n",
            "Epoch:22 Loss:tensor(0.7240, grad_fn=<DivBackward0>)\n",
            "Epoch:23 Loss:tensor(0.7302, grad_fn=<DivBackward0>)\n",
            "Epoch:24 Loss:tensor(0.7112, grad_fn=<DivBackward0>)\n",
            "Epoch:25 Loss:tensor(0.7203, grad_fn=<DivBackward0>)\n",
            "Epoch:26 Loss:tensor(0.7348, grad_fn=<DivBackward0>)\n",
            "Epoch:27 Loss:tensor(0.7148, grad_fn=<DivBackward0>)\n",
            "Epoch:28 Loss:tensor(0.7179, grad_fn=<DivBackward0>)\n",
            "Epoch:29 Loss:tensor(0.7013, grad_fn=<DivBackward0>)\n",
            "Epoch:30 Loss:tensor(0.7025, grad_fn=<DivBackward0>)\n",
            "Epoch:31 Loss:tensor(0.7154, grad_fn=<DivBackward0>)\n",
            "Epoch:32 Loss:tensor(0.7010, grad_fn=<DivBackward0>)\n",
            "Epoch:33 Loss:tensor(0.6862, grad_fn=<DivBackward0>)\n",
            "Epoch:34 Loss:tensor(0.6964, grad_fn=<DivBackward0>)\n",
            "Epoch:35 Loss:tensor(0.6940, grad_fn=<DivBackward0>)\n",
            "Epoch:36 Loss:tensor(0.6767, grad_fn=<DivBackward0>)\n",
            "Epoch:37 Loss:tensor(0.6829, grad_fn=<DivBackward0>)\n",
            "Epoch:38 Loss:tensor(0.6832, grad_fn=<DivBackward0>)\n",
            "Epoch:39 Loss:tensor(0.6849, grad_fn=<DivBackward0>)\n",
            "Epoch:40 Loss:tensor(0.6684, grad_fn=<DivBackward0>)\n",
            "Epoch:41 Loss:tensor(0.6819, grad_fn=<DivBackward0>)\n",
            "Epoch:42 Loss:tensor(0.6725, grad_fn=<DivBackward0>)\n",
            "Epoch:43 Loss:tensor(0.6949, grad_fn=<DivBackward0>)\n",
            "Epoch:44 Loss:tensor(0.6703, grad_fn=<DivBackward0>)\n",
            "Epoch:45 Loss:tensor(0.6780, grad_fn=<DivBackward0>)\n",
            "Epoch:46 Loss:tensor(0.6720, grad_fn=<DivBackward0>)\n",
            "Epoch:47 Loss:tensor(0.6695, grad_fn=<DivBackward0>)\n",
            "Epoch:48 Loss:tensor(0.6575, grad_fn=<DivBackward0>)\n",
            "Epoch:49 Loss:tensor(0.6666, grad_fn=<DivBackward0>)\n",
            "Epoch:50 Loss:tensor(0.6524, grad_fn=<DivBackward0>)\n",
            "Epoch:51 Loss:tensor(0.6466, grad_fn=<DivBackward0>)\n",
            "Epoch:52 Loss:tensor(0.6590, grad_fn=<DivBackward0>)\n",
            "Epoch:53 Loss:tensor(0.6613, grad_fn=<DivBackward0>)\n",
            "Epoch:54 Loss:tensor(0.6834, grad_fn=<DivBackward0>)\n",
            "Epoch:55 Loss:tensor(0.6750, grad_fn=<DivBackward0>)\n",
            "Epoch:56 Loss:tensor(0.6743, grad_fn=<DivBackward0>)\n",
            "Epoch:57 Loss:tensor(0.6619, grad_fn=<DivBackward0>)\n",
            "Epoch:58 Loss:tensor(0.6796, grad_fn=<DivBackward0>)\n",
            "Epoch:59 Loss:tensor(0.6340, grad_fn=<DivBackward0>)\n",
            "Epoch:60 Loss:tensor(0.6395, grad_fn=<DivBackward0>)\n",
            "Epoch:61 Loss:tensor(0.6529, grad_fn=<DivBackward0>)\n",
            "Epoch:62 Loss:tensor(0.6352, grad_fn=<DivBackward0>)\n",
            "Epoch:63 Loss:tensor(0.6547, grad_fn=<DivBackward0>)\n",
            "Epoch:64 Loss:tensor(0.6378, grad_fn=<DivBackward0>)\n",
            "Epoch:65 Loss:tensor(0.6575, grad_fn=<DivBackward0>)\n",
            "Epoch:66 Loss:tensor(0.6353, grad_fn=<DivBackward0>)\n",
            "Epoch:67 Loss:tensor(0.6350, grad_fn=<DivBackward0>)\n",
            "Epoch:68 Loss:tensor(0.6411, grad_fn=<DivBackward0>)\n",
            "Epoch:69 Loss:tensor(0.6476, grad_fn=<DivBackward0>)\n",
            "Epoch:70 Loss:tensor(0.6251, grad_fn=<DivBackward0>)\n",
            "Epoch:71 Loss:tensor(0.6295, grad_fn=<DivBackward0>)\n",
            "Epoch:72 Loss:tensor(0.6309, grad_fn=<DivBackward0>)\n",
            "Epoch:73 Loss:tensor(0.6200, grad_fn=<DivBackward0>)\n",
            "Epoch:74 Loss:tensor(0.6409, grad_fn=<DivBackward0>)\n",
            "Epoch:75 Loss:tensor(0.6327, grad_fn=<DivBackward0>)\n",
            "Epoch:76 Loss:tensor(0.6176, grad_fn=<DivBackward0>)\n",
            "Epoch:77 Loss:tensor(0.6224, grad_fn=<DivBackward0>)\n",
            "Epoch:78 Loss:tensor(0.6273, grad_fn=<DivBackward0>)\n",
            "Epoch:79 Loss:tensor(0.6232, grad_fn=<DivBackward0>)\n",
            "Epoch:80 Loss:tensor(0.6368, grad_fn=<DivBackward0>)\n",
            "Epoch:81 Loss:tensor(0.6239, grad_fn=<DivBackward0>)\n",
            "Epoch:82 Loss:tensor(0.6194, grad_fn=<DivBackward0>)\n",
            "Epoch:83 Loss:tensor(0.6205, grad_fn=<DivBackward0>)\n",
            "Epoch:84 Loss:tensor(0.6102, grad_fn=<DivBackward0>)\n",
            "Epoch:85 Loss:tensor(0.6122, grad_fn=<DivBackward0>)\n",
            "Epoch:86 Loss:tensor(0.6118, grad_fn=<DivBackward0>)\n",
            "Epoch:87 Loss:tensor(0.6251, grad_fn=<DivBackward0>)\n",
            "Epoch:88 Loss:tensor(0.6226, grad_fn=<DivBackward0>)\n",
            "Epoch:89 Loss:tensor(0.6140, grad_fn=<DivBackward0>)\n",
            "Epoch:90 Loss:tensor(0.6073, grad_fn=<DivBackward0>)\n",
            "Epoch:91 Loss:tensor(0.6082, grad_fn=<DivBackward0>)\n",
            "Epoch:92 Loss:tensor(0.6084, grad_fn=<DivBackward0>)\n",
            "Epoch:93 Loss:tensor(0.6156, grad_fn=<DivBackward0>)\n",
            "Epoch:94 Loss:tensor(0.6061, grad_fn=<DivBackward0>)\n",
            "Epoch:95 Loss:tensor(0.6280, grad_fn=<DivBackward0>)\n",
            "Epoch:96 Loss:tensor(0.5930, grad_fn=<DivBackward0>)\n",
            "Epoch:97 Loss:tensor(0.6147, grad_fn=<DivBackward0>)\n",
            "Epoch:98 Loss:tensor(0.5997, grad_fn=<DivBackward0>)\n",
            "Epoch:99 Loss:tensor(0.6054, grad_fn=<DivBackward0>)\n",
            "Epoch:100 Loss:tensor(0.5934, grad_fn=<DivBackward0>)\n",
            "Epoch:101 Loss:tensor(0.5907, grad_fn=<DivBackward0>)\n",
            "Epoch:102 Loss:tensor(0.5901, grad_fn=<DivBackward0>)\n",
            "Epoch:103 Loss:tensor(0.5876, grad_fn=<DivBackward0>)\n",
            "Epoch:104 Loss:tensor(0.6307, grad_fn=<DivBackward0>)\n",
            "Epoch:105 Loss:tensor(0.6165, grad_fn=<DivBackward0>)\n",
            "Epoch:106 Loss:tensor(0.5974, grad_fn=<DivBackward0>)\n",
            "Epoch:107 Loss:tensor(0.5963, grad_fn=<DivBackward0>)\n",
            "Epoch:108 Loss:tensor(0.5987, grad_fn=<DivBackward0>)\n",
            "Epoch:109 Loss:tensor(0.5963, grad_fn=<DivBackward0>)\n",
            "Epoch:110 Loss:tensor(0.6166, grad_fn=<DivBackward0>)\n",
            "Epoch:111 Loss:tensor(0.5958, grad_fn=<DivBackward0>)\n",
            "Epoch:112 Loss:tensor(0.5826, grad_fn=<DivBackward0>)\n",
            "Epoch:113 Loss:tensor(0.6146, grad_fn=<DivBackward0>)\n",
            "Epoch:114 Loss:tensor(0.5908, grad_fn=<DivBackward0>)\n",
            "Epoch:115 Loss:tensor(0.5957, grad_fn=<DivBackward0>)\n",
            "Epoch:116 Loss:tensor(0.5796, grad_fn=<DivBackward0>)\n",
            "Epoch:117 Loss:tensor(0.5973, grad_fn=<DivBackward0>)\n",
            "Epoch:118 Loss:tensor(0.5961, grad_fn=<DivBackward0>)\n",
            "Epoch:119 Loss:tensor(0.5851, grad_fn=<DivBackward0>)\n",
            "Epoch:120 Loss:tensor(0.6179, grad_fn=<DivBackward0>)\n",
            "Epoch:121 Loss:tensor(0.5858, grad_fn=<DivBackward0>)\n",
            "Epoch:122 Loss:tensor(0.5791, grad_fn=<DivBackward0>)\n",
            "Epoch:123 Loss:tensor(0.5805, grad_fn=<DivBackward0>)\n",
            "Epoch:124 Loss:tensor(0.5806, grad_fn=<DivBackward0>)\n",
            "Epoch:125 Loss:tensor(0.5818, grad_fn=<DivBackward0>)\n",
            "Epoch:126 Loss:tensor(0.5953, grad_fn=<DivBackward0>)\n",
            "Epoch:127 Loss:tensor(0.5808, grad_fn=<DivBackward0>)\n",
            "Epoch:128 Loss:tensor(0.5895, grad_fn=<DivBackward0>)\n",
            "Epoch:129 Loss:tensor(0.5770, grad_fn=<DivBackward0>)\n",
            "Epoch:130 Loss:tensor(0.5932, grad_fn=<DivBackward0>)\n",
            "Epoch:131 Loss:tensor(0.5733, grad_fn=<DivBackward0>)\n",
            "Epoch:132 Loss:tensor(0.5839, grad_fn=<DivBackward0>)\n",
            "Epoch:133 Loss:tensor(0.5777, grad_fn=<DivBackward0>)\n",
            "Epoch:134 Loss:tensor(0.5723, grad_fn=<DivBackward0>)\n",
            "Epoch:135 Loss:tensor(0.6134, grad_fn=<DivBackward0>)\n",
            "Epoch:136 Loss:tensor(0.5832, grad_fn=<DivBackward0>)\n",
            "Epoch:137 Loss:tensor(0.5928, grad_fn=<DivBackward0>)\n",
            "Epoch:138 Loss:tensor(0.5787, grad_fn=<DivBackward0>)\n",
            "Epoch:139 Loss:tensor(0.5692, grad_fn=<DivBackward0>)\n",
            "Epoch:140 Loss:tensor(0.5701, grad_fn=<DivBackward0>)\n",
            "Epoch:141 Loss:tensor(0.6114, grad_fn=<DivBackward0>)\n",
            "Epoch:142 Loss:tensor(0.6099, grad_fn=<DivBackward0>)\n",
            "Epoch:143 Loss:tensor(0.5764, grad_fn=<DivBackward0>)\n",
            "Epoch:144 Loss:tensor(0.5656, grad_fn=<DivBackward0>)\n",
            "Epoch:145 Loss:tensor(0.5634, grad_fn=<DivBackward0>)\n",
            "Epoch:146 Loss:tensor(0.5650, grad_fn=<DivBackward0>)\n",
            "Epoch:147 Loss:tensor(0.5618, grad_fn=<DivBackward0>)\n",
            "Epoch:148 Loss:tensor(0.5756, grad_fn=<DivBackward0>)\n",
            "Epoch:149 Loss:tensor(0.5816, grad_fn=<DivBackward0>)\n",
            "Epoch:150 Loss:tensor(0.5568, grad_fn=<DivBackward0>)\n",
            "Epoch:151 Loss:tensor(0.5954, grad_fn=<DivBackward0>)\n",
            "Epoch:152 Loss:tensor(0.5656, grad_fn=<DivBackward0>)\n",
            "Epoch:153 Loss:tensor(0.5639, grad_fn=<DivBackward0>)\n",
            "Epoch:154 Loss:tensor(0.6012, grad_fn=<DivBackward0>)\n",
            "Epoch:155 Loss:tensor(0.6025, grad_fn=<DivBackward0>)\n",
            "Epoch:156 Loss:tensor(0.6031, grad_fn=<DivBackward0>)\n",
            "Epoch:157 Loss:tensor(0.5676, grad_fn=<DivBackward0>)\n",
            "Epoch:158 Loss:tensor(0.5611, grad_fn=<DivBackward0>)\n",
            "Epoch:159 Loss:tensor(0.5787, grad_fn=<DivBackward0>)\n",
            "Epoch:160 Loss:tensor(0.5648, grad_fn=<DivBackward0>)\n",
            "Epoch:161 Loss:tensor(0.5591, grad_fn=<DivBackward0>)\n",
            "Epoch:162 Loss:tensor(0.5892, grad_fn=<DivBackward0>)\n",
            "Epoch:163 Loss:tensor(0.5943, grad_fn=<DivBackward0>)\n",
            "Epoch:164 Loss:tensor(0.5666, grad_fn=<DivBackward0>)\n",
            "Epoch:165 Loss:tensor(0.5518, grad_fn=<DivBackward0>)\n",
            "Epoch:166 Loss:tensor(0.5644, grad_fn=<DivBackward0>)\n",
            "Epoch:167 Loss:tensor(0.5741, grad_fn=<DivBackward0>)\n",
            "Epoch:168 Loss:tensor(0.5737, grad_fn=<DivBackward0>)\n",
            "Epoch:169 Loss:tensor(0.5699, grad_fn=<DivBackward0>)\n",
            "Epoch:170 Loss:tensor(0.5661, grad_fn=<DivBackward0>)\n",
            "Epoch:171 Loss:tensor(0.5542, grad_fn=<DivBackward0>)\n",
            "Epoch:172 Loss:tensor(0.5609, grad_fn=<DivBackward0>)\n",
            "Epoch:173 Loss:tensor(0.5601, grad_fn=<DivBackward0>)\n",
            "Epoch:174 Loss:tensor(0.5657, grad_fn=<DivBackward0>)\n",
            "Epoch:175 Loss:tensor(0.5542, grad_fn=<DivBackward0>)\n",
            "Epoch:176 Loss:tensor(0.5652, grad_fn=<DivBackward0>)\n",
            "Epoch:177 Loss:tensor(0.5633, grad_fn=<DivBackward0>)\n",
            "Epoch:178 Loss:tensor(0.5632, grad_fn=<DivBackward0>)\n",
            "Epoch:179 Loss:tensor(0.5513, grad_fn=<DivBackward0>)\n",
            "Epoch:180 Loss:tensor(0.5639, grad_fn=<DivBackward0>)\n",
            "Epoch:181 Loss:tensor(0.5553, grad_fn=<DivBackward0>)\n",
            "Epoch:182 Loss:tensor(0.5687, grad_fn=<DivBackward0>)\n",
            "Epoch:183 Loss:tensor(0.5572, grad_fn=<DivBackward0>)\n",
            "Epoch:184 Loss:tensor(0.5560, grad_fn=<DivBackward0>)\n",
            "Epoch:185 Loss:tensor(0.5537, grad_fn=<DivBackward0>)\n",
            "Epoch:186 Loss:tensor(0.5552, grad_fn=<DivBackward0>)\n",
            "Epoch:187 Loss:tensor(0.5512, grad_fn=<DivBackward0>)\n",
            "Epoch:188 Loss:tensor(0.5710, grad_fn=<DivBackward0>)\n",
            "Epoch:189 Loss:tensor(0.5544, grad_fn=<DivBackward0>)\n",
            "Epoch:190 Loss:tensor(0.5525, grad_fn=<DivBackward0>)\n",
            "Epoch:191 Loss:tensor(0.5537, grad_fn=<DivBackward0>)\n",
            "Epoch:192 Loss:tensor(0.5483, grad_fn=<DivBackward0>)\n",
            "Epoch:193 Loss:tensor(0.5517, grad_fn=<DivBackward0>)\n",
            "Epoch:194 Loss:tensor(0.5801, grad_fn=<DivBackward0>)\n",
            "Epoch:195 Loss:tensor(0.5385, grad_fn=<DivBackward0>)\n",
            "Epoch:196 Loss:tensor(0.5494, grad_fn=<DivBackward0>)\n",
            "Epoch:197 Loss:tensor(0.5581, grad_fn=<DivBackward0>)\n",
            "Epoch:198 Loss:tensor(0.5459, grad_fn=<DivBackward0>)\n",
            "Epoch:199 Loss:tensor(0.5637, grad_fn=<DivBackward0>)\n",
            "Epoch:200 Loss:tensor(0.5482, grad_fn=<DivBackward0>)\n",
            "Epoch:201 Loss:tensor(0.5424, grad_fn=<DivBackward0>)\n",
            "Epoch:202 Loss:tensor(0.5472, grad_fn=<DivBackward0>)\n",
            "Epoch:203 Loss:tensor(0.5438, grad_fn=<DivBackward0>)\n",
            "Epoch:204 Loss:tensor(0.5935, grad_fn=<DivBackward0>)\n",
            "Epoch:205 Loss:tensor(0.5367, grad_fn=<DivBackward0>)\n",
            "Epoch:206 Loss:tensor(0.5425, grad_fn=<DivBackward0>)\n",
            "Epoch:207 Loss:tensor(0.5355, grad_fn=<DivBackward0>)\n",
            "Epoch:208 Loss:tensor(0.5591, grad_fn=<DivBackward0>)\n",
            "Epoch:209 Loss:tensor(0.5506, grad_fn=<DivBackward0>)\n",
            "Epoch:210 Loss:tensor(0.5346, grad_fn=<DivBackward0>)\n",
            "Epoch:211 Loss:tensor(0.5872, grad_fn=<DivBackward0>)\n",
            "Epoch:212 Loss:tensor(0.5724, grad_fn=<DivBackward0>)\n",
            "Epoch:213 Loss:tensor(0.5534, grad_fn=<DivBackward0>)\n",
            "Epoch:214 Loss:tensor(0.5302, grad_fn=<DivBackward0>)\n",
            "Epoch:215 Loss:tensor(0.5364, grad_fn=<DivBackward0>)\n",
            "Epoch:216 Loss:tensor(0.5410, grad_fn=<DivBackward0>)\n",
            "Epoch:217 Loss:tensor(0.5367, grad_fn=<DivBackward0>)\n",
            "Epoch:218 Loss:tensor(0.5320, grad_fn=<DivBackward0>)\n",
            "Epoch:219 Loss:tensor(0.5652, grad_fn=<DivBackward0>)\n",
            "Epoch:220 Loss:tensor(0.5520, grad_fn=<DivBackward0>)\n",
            "Epoch:221 Loss:tensor(0.5325, grad_fn=<DivBackward0>)\n",
            "Epoch:222 Loss:tensor(0.5459, grad_fn=<DivBackward0>)\n",
            "Epoch:223 Loss:tensor(0.5394, grad_fn=<DivBackward0>)\n",
            "Epoch:224 Loss:tensor(0.5433, grad_fn=<DivBackward0>)\n",
            "Epoch:225 Loss:tensor(0.5442, grad_fn=<DivBackward0>)\n",
            "Epoch:226 Loss:tensor(0.5374, grad_fn=<DivBackward0>)\n",
            "Epoch:227 Loss:tensor(0.5324, grad_fn=<DivBackward0>)\n",
            "Epoch:228 Loss:tensor(0.5696, grad_fn=<DivBackward0>)\n",
            "Epoch:229 Loss:tensor(0.5526, grad_fn=<DivBackward0>)\n",
            "Epoch:230 Loss:tensor(0.5261, grad_fn=<DivBackward0>)\n",
            "Epoch:231 Loss:tensor(0.5583, grad_fn=<DivBackward0>)\n",
            "Epoch:232 Loss:tensor(0.5441, grad_fn=<DivBackward0>)\n",
            "Epoch:233 Loss:tensor(0.5342, grad_fn=<DivBackward0>)\n",
            "Epoch:234 Loss:tensor(0.5365, grad_fn=<DivBackward0>)\n",
            "Epoch:235 Loss:tensor(0.5477, grad_fn=<DivBackward0>)\n",
            "Epoch:236 Loss:tensor(0.5282, grad_fn=<DivBackward0>)\n",
            "Epoch:237 Loss:tensor(0.5180, grad_fn=<DivBackward0>)\n",
            "Epoch:238 Loss:tensor(0.5221, grad_fn=<DivBackward0>)\n",
            "Epoch:239 Loss:tensor(0.5525, grad_fn=<DivBackward0>)\n",
            "Epoch:240 Loss:tensor(0.5337, grad_fn=<DivBackward0>)\n",
            "Epoch:241 Loss:tensor(0.5340, grad_fn=<DivBackward0>)\n",
            "Epoch:242 Loss:tensor(0.5326, grad_fn=<DivBackward0>)\n",
            "Epoch:243 Loss:tensor(0.5371, grad_fn=<DivBackward0>)\n",
            "Epoch:244 Loss:tensor(0.5248, grad_fn=<DivBackward0>)\n",
            "Epoch:245 Loss:tensor(0.5161, grad_fn=<DivBackward0>)\n",
            "Epoch:246 Loss:tensor(0.5220, grad_fn=<DivBackward0>)\n",
            "Epoch:247 Loss:tensor(0.5134, grad_fn=<DivBackward0>)\n",
            "Epoch:248 Loss:tensor(0.5285, grad_fn=<DivBackward0>)\n",
            "Epoch:249 Loss:tensor(0.5356, grad_fn=<DivBackward0>)\n",
            "Epoch:250 Loss:tensor(0.5455, grad_fn=<DivBackward0>)\n",
            "Epoch:251 Loss:tensor(0.5200, grad_fn=<DivBackward0>)\n",
            "Epoch:252 Loss:tensor(0.5464, grad_fn=<DivBackward0>)\n",
            "Epoch:253 Loss:tensor(0.5349, grad_fn=<DivBackward0>)\n",
            "Epoch:254 Loss:tensor(0.5481, grad_fn=<DivBackward0>)\n",
            "Epoch:255 Loss:tensor(0.5518, grad_fn=<DivBackward0>)\n",
            "Epoch:256 Loss:tensor(0.5246, grad_fn=<DivBackward0>)\n",
            "Epoch:257 Loss:tensor(0.5631, grad_fn=<DivBackward0>)\n",
            "Epoch:258 Loss:tensor(0.5329, grad_fn=<DivBackward0>)\n",
            "Epoch:259 Loss:tensor(0.5265, grad_fn=<DivBackward0>)\n",
            "Epoch:260 Loss:tensor(0.5268, grad_fn=<DivBackward0>)\n",
            "Epoch:261 Loss:tensor(0.5159, grad_fn=<DivBackward0>)\n",
            "Epoch:262 Loss:tensor(0.5095, grad_fn=<DivBackward0>)\n",
            "Epoch:263 Loss:tensor(0.5240, grad_fn=<DivBackward0>)\n",
            "Epoch:264 Loss:tensor(0.5208, grad_fn=<DivBackward0>)\n",
            "Epoch:265 Loss:tensor(0.5146, grad_fn=<DivBackward0>)\n",
            "Epoch:266 Loss:tensor(0.5261, grad_fn=<DivBackward0>)\n",
            "Epoch:267 Loss:tensor(0.4963, grad_fn=<DivBackward0>)\n",
            "Epoch:268 Loss:tensor(0.5455, grad_fn=<DivBackward0>)\n",
            "Epoch:269 Loss:tensor(0.5099, grad_fn=<DivBackward0>)\n",
            "Epoch:270 Loss:tensor(0.5014, grad_fn=<DivBackward0>)\n",
            "Epoch:271 Loss:tensor(0.4904, grad_fn=<DivBackward0>)\n",
            "Epoch:272 Loss:tensor(0.5034, grad_fn=<DivBackward0>)\n",
            "Epoch:273 Loss:tensor(0.5340, grad_fn=<DivBackward0>)\n",
            "Epoch:274 Loss:tensor(0.4965, grad_fn=<DivBackward0>)\n",
            "Epoch:275 Loss:tensor(0.5083, grad_fn=<DivBackward0>)\n",
            "Epoch:276 Loss:tensor(0.5013, grad_fn=<DivBackward0>)\n",
            "Epoch:277 Loss:tensor(0.5028, grad_fn=<DivBackward0>)\n",
            "Epoch:278 Loss:tensor(0.5130, grad_fn=<DivBackward0>)\n",
            "Epoch:279 Loss:tensor(0.5167, grad_fn=<DivBackward0>)\n",
            "Epoch:280 Loss:tensor(0.5065, grad_fn=<DivBackward0>)\n",
            "Epoch:281 Loss:tensor(0.4945, grad_fn=<DivBackward0>)\n",
            "Epoch:282 Loss:tensor(0.4980, grad_fn=<DivBackward0>)\n",
            "Epoch:283 Loss:tensor(0.5044, grad_fn=<DivBackward0>)\n",
            "Epoch:284 Loss:tensor(0.4935, grad_fn=<DivBackward0>)\n",
            "Epoch:285 Loss:tensor(0.4978, grad_fn=<DivBackward0>)\n",
            "Epoch:286 Loss:tensor(0.4972, grad_fn=<DivBackward0>)\n",
            "Epoch:287 Loss:tensor(0.5035, grad_fn=<DivBackward0>)\n",
            "Epoch:288 Loss:tensor(0.4820, grad_fn=<DivBackward0>)\n",
            "Epoch:289 Loss:tensor(0.4879, grad_fn=<DivBackward0>)\n",
            "Epoch:290 Loss:tensor(0.4712, grad_fn=<DivBackward0>)\n",
            "Epoch:291 Loss:tensor(0.4820, grad_fn=<DivBackward0>)\n",
            "Epoch:292 Loss:tensor(0.5332, grad_fn=<DivBackward0>)\n",
            "Epoch:293 Loss:tensor(0.4832, grad_fn=<DivBackward0>)\n",
            "Epoch:294 Loss:tensor(0.4588, grad_fn=<DivBackward0>)\n",
            "Epoch:295 Loss:tensor(0.4541, grad_fn=<DivBackward0>)\n",
            "Epoch:296 Loss:tensor(0.4520, grad_fn=<DivBackward0>)\n",
            "Epoch:297 Loss:tensor(0.5297, grad_fn=<DivBackward0>)\n",
            "Epoch:298 Loss:tensor(0.4577, grad_fn=<DivBackward0>)\n",
            "Epoch:299 Loss:tensor(0.4254, grad_fn=<DivBackward0>)\n",
            "Epoch:300 Loss:tensor(0.4366, grad_fn=<DivBackward0>)\n",
            "Epoch:301 Loss:tensor(0.4304, grad_fn=<DivBackward0>)\n",
            "Epoch:302 Loss:tensor(0.4282, grad_fn=<DivBackward0>)\n",
            "Epoch:303 Loss:tensor(0.4287, grad_fn=<DivBackward0>)\n",
            "Epoch:304 Loss:tensor(0.4137, grad_fn=<DivBackward0>)\n",
            "Epoch:305 Loss:tensor(0.4299, grad_fn=<DivBackward0>)\n",
            "Epoch:306 Loss:tensor(0.3969, grad_fn=<DivBackward0>)\n",
            "Epoch:307 Loss:tensor(0.4267, grad_fn=<DivBackward0>)\n",
            "Epoch:308 Loss:tensor(0.4123, grad_fn=<DivBackward0>)\n",
            "Epoch:309 Loss:tensor(0.3802, grad_fn=<DivBackward0>)\n",
            "Epoch:310 Loss:tensor(0.3898, grad_fn=<DivBackward0>)\n",
            "Epoch:311 Loss:tensor(0.3786, grad_fn=<DivBackward0>)\n",
            "Epoch:312 Loss:tensor(0.3778, grad_fn=<DivBackward0>)\n",
            "Epoch:313 Loss:tensor(0.3721, grad_fn=<DivBackward0>)\n",
            "Epoch:314 Loss:tensor(0.3668, grad_fn=<DivBackward0>)\n",
            "Epoch:315 Loss:tensor(0.3759, grad_fn=<DivBackward0>)\n",
            "Epoch:316 Loss:tensor(0.3492, grad_fn=<DivBackward0>)\n",
            "Epoch:317 Loss:tensor(0.3527, grad_fn=<DivBackward0>)\n",
            "Epoch:318 Loss:tensor(0.3710, grad_fn=<DivBackward0>)\n",
            "Epoch:319 Loss:tensor(0.3977, grad_fn=<DivBackward0>)\n",
            "Epoch:320 Loss:tensor(0.3820, grad_fn=<DivBackward0>)\n",
            "Epoch:321 Loss:tensor(0.3600, grad_fn=<DivBackward0>)\n",
            "Epoch:322 Loss:tensor(0.3519, grad_fn=<DivBackward0>)\n",
            "Epoch:323 Loss:tensor(0.3299, grad_fn=<DivBackward0>)\n",
            "Epoch:324 Loss:tensor(0.3206, grad_fn=<DivBackward0>)\n",
            "Epoch:325 Loss:tensor(0.3261, grad_fn=<DivBackward0>)\n",
            "Epoch:326 Loss:tensor(0.3394, grad_fn=<DivBackward0>)\n",
            "Epoch:327 Loss:tensor(0.3273, grad_fn=<DivBackward0>)\n",
            "Epoch:328 Loss:tensor(0.3144, grad_fn=<DivBackward0>)\n",
            "Epoch:329 Loss:tensor(0.3367, grad_fn=<DivBackward0>)\n",
            "Epoch:330 Loss:tensor(0.2990, grad_fn=<DivBackward0>)\n",
            "Epoch:331 Loss:tensor(0.3161, grad_fn=<DivBackward0>)\n",
            "Epoch:332 Loss:tensor(0.3185, grad_fn=<DivBackward0>)\n",
            "Epoch:333 Loss:tensor(0.3116, grad_fn=<DivBackward0>)\n",
            "Epoch:334 Loss:tensor(0.3017, grad_fn=<DivBackward0>)\n",
            "Epoch:335 Loss:tensor(0.3042, grad_fn=<DivBackward0>)\n",
            "Epoch:336 Loss:tensor(0.3054, grad_fn=<DivBackward0>)\n",
            "Epoch:337 Loss:tensor(0.3137, grad_fn=<DivBackward0>)\n",
            "Epoch:338 Loss:tensor(0.2927, grad_fn=<DivBackward0>)\n",
            "Epoch:339 Loss:tensor(0.2863, grad_fn=<DivBackward0>)\n",
            "Epoch:340 Loss:tensor(0.2807, grad_fn=<DivBackward0>)\n",
            "Epoch:341 Loss:tensor(0.3024, grad_fn=<DivBackward0>)\n",
            "Epoch:342 Loss:tensor(0.3049, grad_fn=<DivBackward0>)\n",
            "Epoch:343 Loss:tensor(0.3124, grad_fn=<DivBackward0>)\n",
            "Epoch:344 Loss:tensor(0.2641, grad_fn=<DivBackward0>)\n",
            "Epoch:345 Loss:tensor(0.2696, grad_fn=<DivBackward0>)\n",
            "Epoch:346 Loss:tensor(0.2759, grad_fn=<DivBackward0>)\n",
            "Epoch:347 Loss:tensor(0.2582, grad_fn=<DivBackward0>)\n",
            "Epoch:348 Loss:tensor(0.2570, grad_fn=<DivBackward0>)\n",
            "Epoch:349 Loss:tensor(0.2531, grad_fn=<DivBackward0>)\n",
            "Epoch:350 Loss:tensor(0.2471, grad_fn=<DivBackward0>)\n",
            "Epoch:351 Loss:tensor(0.3427, grad_fn=<DivBackward0>)\n",
            "Epoch:352 Loss:tensor(0.2620, grad_fn=<DivBackward0>)\n",
            "Epoch:353 Loss:tensor(0.2445, grad_fn=<DivBackward0>)\n",
            "Epoch:354 Loss:tensor(0.2554, grad_fn=<DivBackward0>)\n",
            "Epoch:355 Loss:tensor(0.2553, grad_fn=<DivBackward0>)\n",
            "Epoch:356 Loss:tensor(0.2447, grad_fn=<DivBackward0>)\n",
            "Epoch:357 Loss:tensor(0.2284, grad_fn=<DivBackward0>)\n",
            "Epoch:358 Loss:tensor(0.2511, grad_fn=<DivBackward0>)\n",
            "Epoch:359 Loss:tensor(0.2381, grad_fn=<DivBackward0>)\n",
            "Epoch:360 Loss:tensor(0.2615, grad_fn=<DivBackward0>)\n",
            "Epoch:361 Loss:tensor(0.2392, grad_fn=<DivBackward0>)\n",
            "Epoch:362 Loss:tensor(0.2234, grad_fn=<DivBackward0>)\n",
            "Epoch:363 Loss:tensor(0.2310, grad_fn=<DivBackward0>)\n",
            "Epoch:364 Loss:tensor(0.2294, grad_fn=<DivBackward0>)\n",
            "Epoch:365 Loss:tensor(0.2891, grad_fn=<DivBackward0>)\n",
            "Epoch:366 Loss:tensor(0.2416, grad_fn=<DivBackward0>)\n",
            "Epoch:367 Loss:tensor(0.2195, grad_fn=<DivBackward0>)\n",
            "Epoch:368 Loss:tensor(0.2289, grad_fn=<DivBackward0>)\n",
            "Epoch:369 Loss:tensor(0.2287, grad_fn=<DivBackward0>)\n",
            "Epoch:370 Loss:tensor(0.2110, grad_fn=<DivBackward0>)\n",
            "Epoch:371 Loss:tensor(0.2273, grad_fn=<DivBackward0>)\n",
            "Epoch:372 Loss:tensor(0.2375, grad_fn=<DivBackward0>)\n",
            "Epoch:373 Loss:tensor(0.2204, grad_fn=<DivBackward0>)\n",
            "Epoch:374 Loss:tensor(0.2097, grad_fn=<DivBackward0>)\n",
            "Epoch:375 Loss:tensor(0.2228, grad_fn=<DivBackward0>)\n",
            "Epoch:376 Loss:tensor(0.2139, grad_fn=<DivBackward0>)\n",
            "Epoch:377 Loss:tensor(0.2049, grad_fn=<DivBackward0>)\n",
            "Epoch:378 Loss:tensor(0.2073, grad_fn=<DivBackward0>)\n",
            "Epoch:379 Loss:tensor(0.2021, grad_fn=<DivBackward0>)\n",
            "Epoch:380 Loss:tensor(0.2022, grad_fn=<DivBackward0>)\n",
            "Epoch:381 Loss:tensor(0.1826, grad_fn=<DivBackward0>)\n",
            "Epoch:382 Loss:tensor(0.1643, grad_fn=<DivBackward0>)\n",
            "Epoch:383 Loss:tensor(0.1729, grad_fn=<DivBackward0>)\n",
            "Epoch:384 Loss:tensor(0.1834, grad_fn=<DivBackward0>)\n",
            "Epoch:385 Loss:tensor(0.1650, grad_fn=<DivBackward0>)\n",
            "Epoch:386 Loss:tensor(0.1707, grad_fn=<DivBackward0>)\n",
            "Epoch:387 Loss:tensor(0.1674, grad_fn=<DivBackward0>)\n",
            "Epoch:388 Loss:tensor(0.1638, grad_fn=<DivBackward0>)\n",
            "Epoch:389 Loss:tensor(0.1587, grad_fn=<DivBackward0>)\n",
            "Epoch:390 Loss:tensor(0.1559, grad_fn=<DivBackward0>)\n",
            "Epoch:391 Loss:tensor(0.1632, grad_fn=<DivBackward0>)\n",
            "Epoch:392 Loss:tensor(0.1636, grad_fn=<DivBackward0>)\n",
            "Epoch:393 Loss:tensor(0.1577, grad_fn=<DivBackward0>)\n",
            "Epoch:394 Loss:tensor(0.1627, grad_fn=<DivBackward0>)\n",
            "Epoch:395 Loss:tensor(0.1720, grad_fn=<DivBackward0>)\n",
            "Epoch:396 Loss:tensor(0.1637, grad_fn=<DivBackward0>)\n",
            "Epoch:397 Loss:tensor(0.1564, grad_fn=<DivBackward0>)\n",
            "Epoch:398 Loss:tensor(0.1705, grad_fn=<DivBackward0>)\n",
            "Epoch:399 Loss:tensor(0.1392, grad_fn=<DivBackward0>)\n",
            "Epoch:400 Loss:tensor(0.1798, grad_fn=<DivBackward0>)\n",
            "Epoch:401 Loss:tensor(0.2036, grad_fn=<DivBackward0>)\n",
            "Epoch:402 Loss:tensor(0.2049, grad_fn=<DivBackward0>)\n",
            "Epoch:403 Loss:tensor(0.1533, grad_fn=<DivBackward0>)\n",
            "Epoch:404 Loss:tensor(0.1766, grad_fn=<DivBackward0>)\n",
            "Epoch:405 Loss:tensor(0.1786, grad_fn=<DivBackward0>)\n",
            "Epoch:406 Loss:tensor(0.1468, grad_fn=<DivBackward0>)\n",
            "Epoch:407 Loss:tensor(0.1396, grad_fn=<DivBackward0>)\n",
            "Epoch:408 Loss:tensor(0.1599, grad_fn=<DivBackward0>)\n",
            "Epoch:409 Loss:tensor(0.1717, grad_fn=<DivBackward0>)\n",
            "Epoch:410 Loss:tensor(0.1369, grad_fn=<DivBackward0>)\n",
            "Epoch:411 Loss:tensor(0.1365, grad_fn=<DivBackward0>)\n",
            "Epoch:412 Loss:tensor(0.1352, grad_fn=<DivBackward0>)\n",
            "Epoch:413 Loss:tensor(0.1350, grad_fn=<DivBackward0>)\n",
            "Epoch:414 Loss:tensor(0.1319, grad_fn=<DivBackward0>)\n",
            "Epoch:415 Loss:tensor(0.1398, grad_fn=<DivBackward0>)\n",
            "Epoch:416 Loss:tensor(0.1351, grad_fn=<DivBackward0>)\n",
            "Epoch:417 Loss:tensor(0.1536, grad_fn=<DivBackward0>)\n",
            "Epoch:418 Loss:tensor(0.1471, grad_fn=<DivBackward0>)\n",
            "Epoch:419 Loss:tensor(0.1454, grad_fn=<DivBackward0>)\n",
            "Epoch:420 Loss:tensor(0.1487, grad_fn=<DivBackward0>)\n",
            "Epoch:421 Loss:tensor(0.1549, grad_fn=<DivBackward0>)\n",
            "Epoch:422 Loss:tensor(0.1449, grad_fn=<DivBackward0>)\n",
            "Epoch:423 Loss:tensor(0.1245, grad_fn=<DivBackward0>)\n",
            "Epoch:424 Loss:tensor(0.1572, grad_fn=<DivBackward0>)\n",
            "Epoch:425 Loss:tensor(0.1418, grad_fn=<DivBackward0>)\n",
            "Epoch:426 Loss:tensor(0.1595, grad_fn=<DivBackward0>)\n",
            "Epoch:427 Loss:tensor(0.1201, grad_fn=<DivBackward0>)\n",
            "Epoch:428 Loss:tensor(0.1527, grad_fn=<DivBackward0>)\n",
            "Epoch:429 Loss:tensor(0.1633, grad_fn=<DivBackward0>)\n",
            "Epoch:430 Loss:tensor(0.1353, grad_fn=<DivBackward0>)\n",
            "Epoch:431 Loss:tensor(0.1244, grad_fn=<DivBackward0>)\n",
            "Epoch:432 Loss:tensor(0.1162, grad_fn=<DivBackward0>)\n",
            "Epoch:433 Loss:tensor(0.1187, grad_fn=<DivBackward0>)\n",
            "Epoch:434 Loss:tensor(0.1331, grad_fn=<DivBackward0>)\n",
            "Epoch:435 Loss:tensor(0.1858, grad_fn=<DivBackward0>)\n",
            "Epoch:436 Loss:tensor(0.1335, grad_fn=<DivBackward0>)\n",
            "Epoch:437 Loss:tensor(0.1181, grad_fn=<DivBackward0>)\n",
            "Epoch:438 Loss:tensor(0.1238, grad_fn=<DivBackward0>)\n",
            "Epoch:439 Loss:tensor(0.1294, grad_fn=<DivBackward0>)\n",
            "Epoch:440 Loss:tensor(0.1578, grad_fn=<DivBackward0>)\n",
            "Epoch:441 Loss:tensor(0.1637, grad_fn=<DivBackward0>)\n",
            "Epoch:442 Loss:tensor(0.1248, grad_fn=<DivBackward0>)\n",
            "Epoch:443 Loss:tensor(0.1171, grad_fn=<DivBackward0>)\n",
            "Epoch:444 Loss:tensor(0.1176, grad_fn=<DivBackward0>)\n",
            "Epoch:445 Loss:tensor(0.1157, grad_fn=<DivBackward0>)\n",
            "Epoch:446 Loss:tensor(0.1117, grad_fn=<DivBackward0>)\n",
            "Epoch:447 Loss:tensor(0.1196, grad_fn=<DivBackward0>)\n",
            "Epoch:448 Loss:tensor(0.1207, grad_fn=<DivBackward0>)\n",
            "Epoch:449 Loss:tensor(0.1198, grad_fn=<DivBackward0>)\n",
            "Epoch:450 Loss:tensor(0.1195, grad_fn=<DivBackward0>)\n",
            "Epoch:451 Loss:tensor(0.1128, grad_fn=<DivBackward0>)\n",
            "Epoch:452 Loss:tensor(0.1174, grad_fn=<DivBackward0>)\n",
            "Epoch:453 Loss:tensor(0.1437, grad_fn=<DivBackward0>)\n",
            "Epoch:454 Loss:tensor(0.1393, grad_fn=<DivBackward0>)\n",
            "Epoch:455 Loss:tensor(0.1115, grad_fn=<DivBackward0>)\n",
            "Epoch:456 Loss:tensor(0.1146, grad_fn=<DivBackward0>)\n",
            "Epoch:457 Loss:tensor(0.1368, grad_fn=<DivBackward0>)\n",
            "Epoch:458 Loss:tensor(0.1468, grad_fn=<DivBackward0>)\n",
            "Epoch:459 Loss:tensor(0.1288, grad_fn=<DivBackward0>)\n",
            "Epoch:460 Loss:tensor(0.1301, grad_fn=<DivBackward0>)\n",
            "Epoch:461 Loss:tensor(0.1294, grad_fn=<DivBackward0>)\n",
            "Epoch:462 Loss:tensor(0.1164, grad_fn=<DivBackward0>)\n",
            "Epoch:463 Loss:tensor(0.1222, grad_fn=<DivBackward0>)\n",
            "Epoch:464 Loss:tensor(0.1178, grad_fn=<DivBackward0>)\n",
            "Epoch:465 Loss:tensor(0.1308, grad_fn=<DivBackward0>)\n",
            "Epoch:466 Loss:tensor(0.1205, grad_fn=<DivBackward0>)\n",
            "Epoch:467 Loss:tensor(0.1122, grad_fn=<DivBackward0>)\n",
            "Epoch:468 Loss:tensor(0.1031, grad_fn=<DivBackward0>)\n",
            "Epoch:469 Loss:tensor(0.1356, grad_fn=<DivBackward0>)\n",
            "Epoch:470 Loss:tensor(0.1214, grad_fn=<DivBackward0>)\n",
            "Epoch:471 Loss:tensor(0.1122, grad_fn=<DivBackward0>)\n",
            "Epoch:472 Loss:tensor(0.1111, grad_fn=<DivBackward0>)\n",
            "Epoch:473 Loss:tensor(0.1150, grad_fn=<DivBackward0>)\n",
            "Epoch:474 Loss:tensor(0.1241, grad_fn=<DivBackward0>)\n",
            "Epoch:475 Loss:tensor(0.1126, grad_fn=<DivBackward0>)\n",
            "Epoch:476 Loss:tensor(0.1072, grad_fn=<DivBackward0>)\n",
            "Epoch:477 Loss:tensor(0.1105, grad_fn=<DivBackward0>)\n",
            "Epoch:478 Loss:tensor(0.1004, grad_fn=<DivBackward0>)\n",
            "Epoch:479 Loss:tensor(0.1060, grad_fn=<DivBackward0>)\n",
            "Epoch:480 Loss:tensor(0.1113, grad_fn=<DivBackward0>)\n",
            "Epoch:481 Loss:tensor(0.1041, grad_fn=<DivBackward0>)\n",
            "Epoch:482 Loss:tensor(0.0975, grad_fn=<DivBackward0>)\n",
            "Epoch:483 Loss:tensor(0.1073, grad_fn=<DivBackward0>)\n",
            "Epoch:484 Loss:tensor(0.1048, grad_fn=<DivBackward0>)\n",
            "Epoch:485 Loss:tensor(0.0993, grad_fn=<DivBackward0>)\n",
            "Epoch:486 Loss:tensor(0.1613, grad_fn=<DivBackward0>)\n",
            "Epoch:487 Loss:tensor(0.1287, grad_fn=<DivBackward0>)\n",
            "Epoch:488 Loss:tensor(0.1375, grad_fn=<DivBackward0>)\n",
            "Epoch:489 Loss:tensor(0.1123, grad_fn=<DivBackward0>)\n",
            "Epoch:490 Loss:tensor(0.1091, grad_fn=<DivBackward0>)\n",
            "Epoch:491 Loss:tensor(0.1119, grad_fn=<DivBackward0>)\n",
            "Epoch:492 Loss:tensor(0.1034, grad_fn=<DivBackward0>)\n",
            "Epoch:493 Loss:tensor(0.1031, grad_fn=<DivBackward0>)\n",
            "Epoch:494 Loss:tensor(0.0951, grad_fn=<DivBackward0>)\n",
            "Epoch:495 Loss:tensor(0.1273, grad_fn=<DivBackward0>)\n",
            "Epoch:496 Loss:tensor(0.1256, grad_fn=<DivBackward0>)\n",
            "Epoch:497 Loss:tensor(0.1116, grad_fn=<DivBackward0>)\n",
            "Epoch:498 Loss:tensor(0.1046, grad_fn=<DivBackward0>)\n",
            "Epoch:499 Loss:tensor(0.1000, grad_fn=<DivBackward0>)\n",
            "Epoch:500 Loss:tensor(0.0926, grad_fn=<DivBackward0>)\n",
            "Epoch:501 Loss:tensor(0.1085, grad_fn=<DivBackward0>)\n",
            "Epoch:502 Loss:tensor(0.1033, grad_fn=<DivBackward0>)\n",
            "Epoch:503 Loss:tensor(0.0976, grad_fn=<DivBackward0>)\n",
            "Epoch:504 Loss:tensor(0.1049, grad_fn=<DivBackward0>)\n",
            "Epoch:505 Loss:tensor(0.0986, grad_fn=<DivBackward0>)\n",
            "Epoch:506 Loss:tensor(0.1035, grad_fn=<DivBackward0>)\n",
            "Epoch:507 Loss:tensor(0.1327, grad_fn=<DivBackward0>)\n",
            "Epoch:508 Loss:tensor(0.1118, grad_fn=<DivBackward0>)\n",
            "Epoch:509 Loss:tensor(0.0973, grad_fn=<DivBackward0>)\n",
            "Epoch:510 Loss:tensor(0.0965, grad_fn=<DivBackward0>)\n",
            "Epoch:511 Loss:tensor(0.1008, grad_fn=<DivBackward0>)\n",
            "Epoch:512 Loss:tensor(0.0979, grad_fn=<DivBackward0>)\n",
            "Epoch:513 Loss:tensor(0.1005, grad_fn=<DivBackward0>)\n",
            "Epoch:514 Loss:tensor(0.1142, grad_fn=<DivBackward0>)\n",
            "Epoch:515 Loss:tensor(0.1122, grad_fn=<DivBackward0>)\n",
            "Epoch:516 Loss:tensor(0.2108, grad_fn=<DivBackward0>)\n",
            "Epoch:517 Loss:tensor(0.1517, grad_fn=<DivBackward0>)\n",
            "Epoch:518 Loss:tensor(0.1840, grad_fn=<DivBackward0>)\n",
            "Epoch:519 Loss:tensor(0.1466, grad_fn=<DivBackward0>)\n",
            "Epoch:520 Loss:tensor(0.1011, grad_fn=<DivBackward0>)\n",
            "Epoch:521 Loss:tensor(0.1058, grad_fn=<DivBackward0>)\n",
            "Epoch:522 Loss:tensor(0.0903, grad_fn=<DivBackward0>)\n",
            "Epoch:523 Loss:tensor(0.1091, grad_fn=<DivBackward0>)\n",
            "Epoch:524 Loss:tensor(0.0945, grad_fn=<DivBackward0>)\n",
            "Epoch:525 Loss:tensor(0.1041, grad_fn=<DivBackward0>)\n",
            "Epoch:526 Loss:tensor(0.0976, grad_fn=<DivBackward0>)\n",
            "Epoch:527 Loss:tensor(0.1046, grad_fn=<DivBackward0>)\n",
            "Epoch:528 Loss:tensor(0.0907, grad_fn=<DivBackward0>)\n",
            "Epoch:529 Loss:tensor(0.1008, grad_fn=<DivBackward0>)\n",
            "Epoch:530 Loss:tensor(0.1053, grad_fn=<DivBackward0>)\n",
            "Epoch:531 Loss:tensor(0.1348, grad_fn=<DivBackward0>)\n",
            "Epoch:532 Loss:tensor(0.2748, grad_fn=<DivBackward0>)\n",
            "Epoch:533 Loss:tensor(0.0943, grad_fn=<DivBackward0>)\n",
            "Epoch:534 Loss:tensor(0.0943, grad_fn=<DivBackward0>)\n",
            "Epoch:535 Loss:tensor(0.0984, grad_fn=<DivBackward0>)\n",
            "Epoch:536 Loss:tensor(0.0983, grad_fn=<DivBackward0>)\n",
            "Epoch:537 Loss:tensor(0.0881, grad_fn=<DivBackward0>)\n",
            "Epoch:538 Loss:tensor(0.0960, grad_fn=<DivBackward0>)\n",
            "Epoch:539 Loss:tensor(0.0936, grad_fn=<DivBackward0>)\n",
            "Epoch:540 Loss:tensor(0.0974, grad_fn=<DivBackward0>)\n",
            "Epoch:541 Loss:tensor(0.1051, grad_fn=<DivBackward0>)\n",
            "Epoch:542 Loss:tensor(0.0951, grad_fn=<DivBackward0>)\n",
            "Epoch:543 Loss:tensor(0.0861, grad_fn=<DivBackward0>)\n",
            "Epoch:544 Loss:tensor(0.0999, grad_fn=<DivBackward0>)\n",
            "Epoch:545 Loss:tensor(0.1211, grad_fn=<DivBackward0>)\n",
            "Epoch:546 Loss:tensor(0.2075, grad_fn=<DivBackward0>)\n",
            "Epoch:547 Loss:tensor(0.1272, grad_fn=<DivBackward0>)\n",
            "Epoch:548 Loss:tensor(0.0957, grad_fn=<DivBackward0>)\n",
            "Epoch:549 Loss:tensor(0.0990, grad_fn=<DivBackward0>)\n",
            "Epoch:550 Loss:tensor(0.0952, grad_fn=<DivBackward0>)\n",
            "Epoch:551 Loss:tensor(0.1005, grad_fn=<DivBackward0>)\n",
            "Epoch:552 Loss:tensor(0.1006, grad_fn=<DivBackward0>)\n",
            "Epoch:553 Loss:tensor(0.0866, grad_fn=<DivBackward0>)\n",
            "Epoch:554 Loss:tensor(0.0904, grad_fn=<DivBackward0>)\n",
            "Epoch:555 Loss:tensor(0.0941, grad_fn=<DivBackward0>)\n",
            "Epoch:556 Loss:tensor(0.1032, grad_fn=<DivBackward0>)\n",
            "Epoch:557 Loss:tensor(0.0927, grad_fn=<DivBackward0>)\n",
            "Epoch:558 Loss:tensor(0.0874, grad_fn=<DivBackward0>)\n",
            "Epoch:559 Loss:tensor(0.0923, grad_fn=<DivBackward0>)\n",
            "Epoch:560 Loss:tensor(0.0946, grad_fn=<DivBackward0>)\n",
            "Epoch:561 Loss:tensor(0.1005, grad_fn=<DivBackward0>)\n",
            "Epoch:562 Loss:tensor(0.0856, grad_fn=<DivBackward0>)\n",
            "Epoch:563 Loss:tensor(0.0983, grad_fn=<DivBackward0>)\n",
            "Epoch:564 Loss:tensor(0.0863, grad_fn=<DivBackward0>)\n",
            "Epoch:565 Loss:tensor(0.0959, grad_fn=<DivBackward0>)\n",
            "Epoch:566 Loss:tensor(0.0909, grad_fn=<DivBackward0>)\n",
            "Epoch:567 Loss:tensor(0.0986, grad_fn=<DivBackward0>)\n",
            "Epoch:568 Loss:tensor(0.1297, grad_fn=<DivBackward0>)\n",
            "Epoch:569 Loss:tensor(0.1295, grad_fn=<DivBackward0>)\n",
            "Epoch:570 Loss:tensor(0.0907, grad_fn=<DivBackward0>)\n",
            "Epoch:571 Loss:tensor(0.0979, grad_fn=<DivBackward0>)\n",
            "Epoch:572 Loss:tensor(0.0891, grad_fn=<DivBackward0>)\n",
            "Epoch:573 Loss:tensor(0.0872, grad_fn=<DivBackward0>)\n",
            "Epoch:574 Loss:tensor(0.0958, grad_fn=<DivBackward0>)\n",
            "Epoch:575 Loss:tensor(0.2271, grad_fn=<DivBackward0>)\n",
            "Epoch:576 Loss:tensor(0.1221, grad_fn=<DivBackward0>)\n",
            "Epoch:577 Loss:tensor(0.0890, grad_fn=<DivBackward0>)\n",
            "Epoch:578 Loss:tensor(0.0917, grad_fn=<DivBackward0>)\n",
            "Epoch:579 Loss:tensor(0.0884, grad_fn=<DivBackward0>)\n",
            "Epoch:580 Loss:tensor(0.1167, grad_fn=<DivBackward0>)\n",
            "Epoch:581 Loss:tensor(0.0924, grad_fn=<DivBackward0>)\n",
            "Epoch:582 Loss:tensor(0.0876, grad_fn=<DivBackward0>)\n",
            "Epoch:583 Loss:tensor(0.0836, grad_fn=<DivBackward0>)\n",
            "Epoch:584 Loss:tensor(0.0828, grad_fn=<DivBackward0>)\n",
            "Epoch:585 Loss:tensor(0.0879, grad_fn=<DivBackward0>)\n",
            "Epoch:586 Loss:tensor(0.0804, grad_fn=<DivBackward0>)\n",
            "Epoch:587 Loss:tensor(0.0926, grad_fn=<DivBackward0>)\n",
            "Epoch:588 Loss:tensor(0.0855, grad_fn=<DivBackward0>)\n",
            "Epoch:589 Loss:tensor(0.0834, grad_fn=<DivBackward0>)\n",
            "Epoch:590 Loss:tensor(0.0880, grad_fn=<DivBackward0>)\n",
            "Epoch:591 Loss:tensor(0.0872, grad_fn=<DivBackward0>)\n",
            "Epoch:592 Loss:tensor(0.1943, grad_fn=<DivBackward0>)\n",
            "Epoch:593 Loss:tensor(0.1099, grad_fn=<DivBackward0>)\n",
            "Epoch:594 Loss:tensor(0.0886, grad_fn=<DivBackward0>)\n",
            "Epoch:595 Loss:tensor(0.0902, grad_fn=<DivBackward0>)\n",
            "Epoch:596 Loss:tensor(0.0934, grad_fn=<DivBackward0>)\n",
            "Epoch:597 Loss:tensor(0.0986, grad_fn=<DivBackward0>)\n",
            "Epoch:598 Loss:tensor(0.0857, grad_fn=<DivBackward0>)\n",
            "Epoch:599 Loss:tensor(0.0897, grad_fn=<DivBackward0>)\n",
            "Epoch:600 Loss:tensor(0.0904, grad_fn=<DivBackward0>)\n",
            "Epoch:601 Loss:tensor(0.0824, grad_fn=<DivBackward0>)\n",
            "Epoch:602 Loss:tensor(0.0823, grad_fn=<DivBackward0>)\n",
            "Epoch:603 Loss:tensor(0.0952, grad_fn=<DivBackward0>)\n",
            "Epoch:604 Loss:tensor(0.0907, grad_fn=<DivBackward0>)\n",
            "Epoch:605 Loss:tensor(0.0864, grad_fn=<DivBackward0>)\n",
            "Epoch:606 Loss:tensor(0.0896, grad_fn=<DivBackward0>)\n",
            "Epoch:607 Loss:tensor(0.0850, grad_fn=<DivBackward0>)\n",
            "Epoch:608 Loss:tensor(0.0840, grad_fn=<DivBackward0>)\n",
            "Epoch:609 Loss:tensor(0.0888, grad_fn=<DivBackward0>)\n",
            "Epoch:610 Loss:tensor(0.1387, grad_fn=<DivBackward0>)\n",
            "Epoch:611 Loss:tensor(0.0924, grad_fn=<DivBackward0>)\n",
            "Epoch:612 Loss:tensor(0.0884, grad_fn=<DivBackward0>)\n",
            "Epoch:613 Loss:tensor(0.0815, grad_fn=<DivBackward0>)\n",
            "Epoch:614 Loss:tensor(0.0914, grad_fn=<DivBackward0>)\n",
            "Epoch:615 Loss:tensor(0.0918, grad_fn=<DivBackward0>)\n",
            "Epoch:616 Loss:tensor(0.1001, grad_fn=<DivBackward0>)\n",
            "Epoch:617 Loss:tensor(0.1133, grad_fn=<DivBackward0>)\n",
            "Epoch:618 Loss:tensor(0.0992, grad_fn=<DivBackward0>)\n",
            "Epoch:619 Loss:tensor(0.0874, grad_fn=<DivBackward0>)\n",
            "Epoch:620 Loss:tensor(0.0818, grad_fn=<DivBackward0>)\n",
            "Epoch:621 Loss:tensor(0.0784, grad_fn=<DivBackward0>)\n",
            "Epoch:622 Loss:tensor(0.1209, grad_fn=<DivBackward0>)\n",
            "Epoch:623 Loss:tensor(0.1303, grad_fn=<DivBackward0>)\n",
            "Epoch:624 Loss:tensor(0.0886, grad_fn=<DivBackward0>)\n",
            "Epoch:625 Loss:tensor(0.1340, grad_fn=<DivBackward0>)\n",
            "Epoch:626 Loss:tensor(0.1081, grad_fn=<DivBackward0>)\n",
            "Epoch:627 Loss:tensor(0.0815, grad_fn=<DivBackward0>)\n",
            "Epoch:628 Loss:tensor(0.0904, grad_fn=<DivBackward0>)\n",
            "Epoch:629 Loss:tensor(0.0812, grad_fn=<DivBackward0>)\n",
            "Epoch:630 Loss:tensor(0.1067, grad_fn=<DivBackward0>)\n",
            "Epoch:631 Loss:tensor(0.0877, grad_fn=<DivBackward0>)\n",
            "Epoch:632 Loss:tensor(0.0813, grad_fn=<DivBackward0>)\n",
            "Epoch:633 Loss:tensor(0.0755, grad_fn=<DivBackward0>)\n",
            "Epoch:634 Loss:tensor(0.0895, grad_fn=<DivBackward0>)\n",
            "Epoch:635 Loss:tensor(0.0824, grad_fn=<DivBackward0>)\n",
            "Epoch:636 Loss:tensor(0.0756, grad_fn=<DivBackward0>)\n",
            "Epoch:637 Loss:tensor(0.0879, grad_fn=<DivBackward0>)\n",
            "Epoch:638 Loss:tensor(0.0848, grad_fn=<DivBackward0>)\n",
            "Epoch:639 Loss:tensor(0.0889, grad_fn=<DivBackward0>)\n",
            "Epoch:640 Loss:tensor(0.1139, grad_fn=<DivBackward0>)\n",
            "Epoch:641 Loss:tensor(0.0934, grad_fn=<DivBackward0>)\n",
            "Epoch:642 Loss:tensor(0.1017, grad_fn=<DivBackward0>)\n",
            "Epoch:643 Loss:tensor(0.0820, grad_fn=<DivBackward0>)\n",
            "Epoch:644 Loss:tensor(0.0944, grad_fn=<DivBackward0>)\n",
            "Epoch:645 Loss:tensor(0.3410, grad_fn=<DivBackward0>)\n",
            "Epoch:646 Loss:tensor(0.0928, grad_fn=<DivBackward0>)\n",
            "Epoch:647 Loss:tensor(0.1008, grad_fn=<DivBackward0>)\n",
            "Epoch:648 Loss:tensor(0.0798, grad_fn=<DivBackward0>)\n",
            "Epoch:649 Loss:tensor(0.0804, grad_fn=<DivBackward0>)\n",
            "Epoch:650 Loss:tensor(0.0799, grad_fn=<DivBackward0>)\n",
            "Epoch:651 Loss:tensor(0.0817, grad_fn=<DivBackward0>)\n",
            "Epoch:652 Loss:tensor(0.0815, grad_fn=<DivBackward0>)\n",
            "Epoch:653 Loss:tensor(0.0824, grad_fn=<DivBackward0>)\n",
            "Epoch:654 Loss:tensor(0.0780, grad_fn=<DivBackward0>)\n",
            "Epoch:655 Loss:tensor(0.0836, grad_fn=<DivBackward0>)\n",
            "Epoch:656 Loss:tensor(0.0836, grad_fn=<DivBackward0>)\n",
            "Epoch:657 Loss:tensor(0.1079, grad_fn=<DivBackward0>)\n",
            "Epoch:658 Loss:tensor(0.0967, grad_fn=<DivBackward0>)\n",
            "Epoch:659 Loss:tensor(0.0876, grad_fn=<DivBackward0>)\n",
            "Epoch:660 Loss:tensor(0.0935, grad_fn=<DivBackward0>)\n",
            "Epoch:661 Loss:tensor(0.1043, grad_fn=<DivBackward0>)\n",
            "Epoch:662 Loss:tensor(0.0840, grad_fn=<DivBackward0>)\n",
            "Epoch:663 Loss:tensor(0.0839, grad_fn=<DivBackward0>)\n",
            "Epoch:664 Loss:tensor(0.0767, grad_fn=<DivBackward0>)\n",
            "Epoch:665 Loss:tensor(0.0759, grad_fn=<DivBackward0>)\n",
            "Epoch:666 Loss:tensor(0.0868, grad_fn=<DivBackward0>)\n",
            "Epoch:667 Loss:tensor(0.0917, grad_fn=<DivBackward0>)\n",
            "Epoch:668 Loss:tensor(0.0817, grad_fn=<DivBackward0>)\n",
            "Epoch:669 Loss:tensor(0.0772, grad_fn=<DivBackward0>)\n",
            "Epoch:670 Loss:tensor(0.1022, grad_fn=<DivBackward0>)\n",
            "Epoch:671 Loss:tensor(0.1070, grad_fn=<DivBackward0>)\n",
            "Epoch:672 Loss:tensor(0.0753, grad_fn=<DivBackward0>)\n",
            "Epoch:673 Loss:tensor(0.0793, grad_fn=<DivBackward0>)\n",
            "Epoch:674 Loss:tensor(0.0893, grad_fn=<DivBackward0>)\n",
            "Epoch:675 Loss:tensor(0.0966, grad_fn=<DivBackward0>)\n",
            "Epoch:676 Loss:tensor(0.0891, grad_fn=<DivBackward0>)\n",
            "Epoch:677 Loss:tensor(0.0808, grad_fn=<DivBackward0>)\n",
            "Epoch:678 Loss:tensor(0.0785, grad_fn=<DivBackward0>)\n",
            "Epoch:679 Loss:tensor(0.4031, grad_fn=<DivBackward0>)\n",
            "Epoch:680 Loss:tensor(0.2437, grad_fn=<DivBackward0>)\n",
            "Epoch:681 Loss:tensor(0.1167, grad_fn=<DivBackward0>)\n",
            "Epoch:682 Loss:tensor(0.1015, grad_fn=<DivBackward0>)\n",
            "Epoch:683 Loss:tensor(0.0737, grad_fn=<DivBackward0>)\n",
            "Epoch:684 Loss:tensor(0.0735, grad_fn=<DivBackward0>)\n",
            "Epoch:685 Loss:tensor(0.0906, grad_fn=<DivBackward0>)\n",
            "Epoch:686 Loss:tensor(0.0775, grad_fn=<DivBackward0>)\n",
            "Epoch:687 Loss:tensor(0.0756, grad_fn=<DivBackward0>)\n",
            "Epoch:688 Loss:tensor(0.0834, grad_fn=<DivBackward0>)\n",
            "Epoch:689 Loss:tensor(0.0817, grad_fn=<DivBackward0>)\n",
            "Epoch:690 Loss:tensor(0.0792, grad_fn=<DivBackward0>)\n",
            "Epoch:691 Loss:tensor(0.0760, grad_fn=<DivBackward0>)\n",
            "Epoch:692 Loss:tensor(0.0770, grad_fn=<DivBackward0>)\n",
            "Epoch:693 Loss:tensor(0.0768, grad_fn=<DivBackward0>)\n",
            "Epoch:694 Loss:tensor(0.0844, grad_fn=<DivBackward0>)\n",
            "Epoch:695 Loss:tensor(0.0899, grad_fn=<DivBackward0>)\n",
            "Epoch:696 Loss:tensor(0.0852, grad_fn=<DivBackward0>)\n",
            "Epoch:697 Loss:tensor(0.0793, grad_fn=<DivBackward0>)\n",
            "Epoch:698 Loss:tensor(0.0801, grad_fn=<DivBackward0>)\n",
            "Epoch:699 Loss:tensor(0.0808, grad_fn=<DivBackward0>)\n",
            "Epoch:700 Loss:tensor(0.0800, grad_fn=<DivBackward0>)\n",
            "Epoch:701 Loss:tensor(0.0838, grad_fn=<DivBackward0>)\n",
            "Epoch:702 Loss:tensor(0.0766, grad_fn=<DivBackward0>)\n",
            "Epoch:703 Loss:tensor(0.0776, grad_fn=<DivBackward0>)\n",
            "Epoch:704 Loss:tensor(0.0749, grad_fn=<DivBackward0>)\n",
            "Epoch:705 Loss:tensor(0.0722, grad_fn=<DivBackward0>)\n",
            "Epoch:706 Loss:tensor(0.0829, grad_fn=<DivBackward0>)\n",
            "Epoch:707 Loss:tensor(0.0907, grad_fn=<DivBackward0>)\n",
            "Epoch:708 Loss:tensor(0.0835, grad_fn=<DivBackward0>)\n",
            "Epoch:709 Loss:tensor(0.1665, grad_fn=<DivBackward0>)\n",
            "Epoch:710 Loss:tensor(0.1287, grad_fn=<DivBackward0>)\n",
            "Epoch:711 Loss:tensor(0.1001, grad_fn=<DivBackward0>)\n",
            "Epoch:712 Loss:tensor(0.0886, grad_fn=<DivBackward0>)\n",
            "Epoch:713 Loss:tensor(0.0824, grad_fn=<DivBackward0>)\n",
            "Epoch:714 Loss:tensor(0.0794, grad_fn=<DivBackward0>)\n",
            "Epoch:715 Loss:tensor(0.0746, grad_fn=<DivBackward0>)\n",
            "Epoch:716 Loss:tensor(0.0751, grad_fn=<DivBackward0>)\n",
            "Epoch:717 Loss:tensor(0.0755, grad_fn=<DivBackward0>)\n",
            "Epoch:718 Loss:tensor(0.0721, grad_fn=<DivBackward0>)\n",
            "Epoch:719 Loss:tensor(0.0755, grad_fn=<DivBackward0>)\n",
            "Epoch:720 Loss:tensor(0.0780, grad_fn=<DivBackward0>)\n",
            "Epoch:721 Loss:tensor(0.0819, grad_fn=<DivBackward0>)\n",
            "Epoch:722 Loss:tensor(0.0796, grad_fn=<DivBackward0>)\n",
            "Epoch:723 Loss:tensor(0.0781, grad_fn=<DivBackward0>)\n",
            "Epoch:724 Loss:tensor(0.0768, grad_fn=<DivBackward0>)\n",
            "Epoch:725 Loss:tensor(0.0732, grad_fn=<DivBackward0>)\n",
            "Epoch:726 Loss:tensor(0.0801, grad_fn=<DivBackward0>)\n",
            "Epoch:727 Loss:tensor(0.0820, grad_fn=<DivBackward0>)\n",
            "Epoch:728 Loss:tensor(0.0796, grad_fn=<DivBackward0>)\n",
            "Epoch:729 Loss:tensor(0.0784, grad_fn=<DivBackward0>)\n",
            "Epoch:730 Loss:tensor(0.0840, grad_fn=<DivBackward0>)\n",
            "Epoch:731 Loss:tensor(0.0810, grad_fn=<DivBackward0>)\n",
            "Epoch:732 Loss:tensor(0.0818, grad_fn=<DivBackward0>)\n",
            "Epoch:733 Loss:tensor(0.0734, grad_fn=<DivBackward0>)\n",
            "Epoch:734 Loss:tensor(0.0928, grad_fn=<DivBackward0>)\n",
            "Epoch:735 Loss:tensor(0.0795, grad_fn=<DivBackward0>)\n",
            "Epoch:736 Loss:tensor(0.0726, grad_fn=<DivBackward0>)\n",
            "Epoch:737 Loss:tensor(0.0851, grad_fn=<DivBackward0>)\n",
            "Epoch:738 Loss:tensor(0.2821, grad_fn=<DivBackward0>)\n",
            "Epoch:739 Loss:tensor(0.4507, grad_fn=<DivBackward0>)\n",
            "Epoch:740 Loss:tensor(0.0885, grad_fn=<DivBackward0>)\n",
            "Epoch:741 Loss:tensor(0.0783, grad_fn=<DivBackward0>)\n",
            "Epoch:742 Loss:tensor(0.1060, grad_fn=<DivBackward0>)\n",
            "Epoch:743 Loss:tensor(0.0751, grad_fn=<DivBackward0>)\n",
            "Epoch:744 Loss:tensor(0.0728, grad_fn=<DivBackward0>)\n",
            "Epoch:745 Loss:tensor(0.0784, grad_fn=<DivBackward0>)\n",
            "Epoch:746 Loss:tensor(0.0755, grad_fn=<DivBackward0>)\n",
            "Epoch:747 Loss:tensor(0.0752, grad_fn=<DivBackward0>)\n",
            "Epoch:748 Loss:tensor(0.0745, grad_fn=<DivBackward0>)\n",
            "Epoch:749 Loss:tensor(0.0780, grad_fn=<DivBackward0>)\n",
            "Epoch:750 Loss:tensor(0.0769, grad_fn=<DivBackward0>)\n",
            "Epoch:751 Loss:tensor(0.0835, grad_fn=<DivBackward0>)\n",
            "Epoch:752 Loss:tensor(0.0884, grad_fn=<DivBackward0>)\n",
            "Epoch:753 Loss:tensor(0.1136, grad_fn=<DivBackward0>)\n",
            "Epoch:754 Loss:tensor(0.1068, grad_fn=<DivBackward0>)\n",
            "Epoch:755 Loss:tensor(0.1456, grad_fn=<DivBackward0>)\n",
            "Epoch:756 Loss:tensor(0.1856, grad_fn=<DivBackward0>)\n",
            "Epoch:757 Loss:tensor(0.0675, grad_fn=<DivBackward0>)\n",
            "Epoch:758 Loss:tensor(0.0879, grad_fn=<DivBackward0>)\n",
            "Epoch:759 Loss:tensor(0.1557, grad_fn=<DivBackward0>)\n",
            "Epoch:760 Loss:tensor(0.1230, grad_fn=<DivBackward0>)\n",
            "Epoch:761 Loss:tensor(0.0770, grad_fn=<DivBackward0>)\n",
            "Epoch:762 Loss:tensor(0.0718, grad_fn=<DivBackward0>)\n",
            "Epoch:763 Loss:tensor(0.0751, grad_fn=<DivBackward0>)\n",
            "Epoch:764 Loss:tensor(0.0756, grad_fn=<DivBackward0>)\n",
            "Epoch:765 Loss:tensor(0.0724, grad_fn=<DivBackward0>)\n",
            "Epoch:766 Loss:tensor(0.0761, grad_fn=<DivBackward0>)\n",
            "Epoch:767 Loss:tensor(0.0766, grad_fn=<DivBackward0>)\n",
            "Epoch:768 Loss:tensor(0.0720, grad_fn=<DivBackward0>)\n",
            "Epoch:769 Loss:tensor(0.0719, grad_fn=<DivBackward0>)\n",
            "Epoch:770 Loss:tensor(0.0694, grad_fn=<DivBackward0>)\n",
            "Epoch:771 Loss:tensor(0.0821, grad_fn=<DivBackward0>)\n",
            "Epoch:772 Loss:tensor(0.0829, grad_fn=<DivBackward0>)\n",
            "Epoch:773 Loss:tensor(0.0716, grad_fn=<DivBackward0>)\n",
            "Epoch:774 Loss:tensor(0.0801, grad_fn=<DivBackward0>)\n",
            "Epoch:775 Loss:tensor(0.0883, grad_fn=<DivBackward0>)\n",
            "Epoch:776 Loss:tensor(0.0788, grad_fn=<DivBackward0>)\n",
            "Epoch:777 Loss:tensor(0.0737, grad_fn=<DivBackward0>)\n",
            "Epoch:778 Loss:tensor(0.0759, grad_fn=<DivBackward0>)\n",
            "Epoch:779 Loss:tensor(0.0743, grad_fn=<DivBackward0>)\n",
            "Epoch:780 Loss:tensor(0.0829, grad_fn=<DivBackward0>)\n",
            "Epoch:781 Loss:tensor(0.0907, grad_fn=<DivBackward0>)\n",
            "Epoch:782 Loss:tensor(0.1839, grad_fn=<DivBackward0>)\n",
            "Epoch:783 Loss:tensor(0.0994, grad_fn=<DivBackward0>)\n",
            "Epoch:784 Loss:tensor(0.0963, grad_fn=<DivBackward0>)\n",
            "Epoch:785 Loss:tensor(0.0773, grad_fn=<DivBackward0>)\n",
            "Epoch:786 Loss:tensor(0.0917, grad_fn=<DivBackward0>)\n",
            "Epoch:787 Loss:tensor(0.0750, grad_fn=<DivBackward0>)\n",
            "Epoch:788 Loss:tensor(0.0862, grad_fn=<DivBackward0>)\n",
            "Epoch:789 Loss:tensor(0.0713, grad_fn=<DivBackward0>)\n",
            "Epoch:790 Loss:tensor(0.0696, grad_fn=<DivBackward0>)\n",
            "Epoch:791 Loss:tensor(0.0816, grad_fn=<DivBackward0>)\n",
            "Epoch:792 Loss:tensor(0.0761, grad_fn=<DivBackward0>)\n",
            "Epoch:793 Loss:tensor(0.0775, grad_fn=<DivBackward0>)\n",
            "Epoch:794 Loss:tensor(0.0957, grad_fn=<DivBackward0>)\n",
            "Epoch:795 Loss:tensor(0.0688, grad_fn=<DivBackward0>)\n",
            "Epoch:796 Loss:tensor(0.0777, grad_fn=<DivBackward0>)\n",
            "Epoch:797 Loss:tensor(0.0683, grad_fn=<DivBackward0>)\n",
            "Epoch:798 Loss:tensor(0.0710, grad_fn=<DivBackward0>)\n",
            "Epoch:799 Loss:tensor(0.0778, grad_fn=<DivBackward0>)\n",
            "Epoch:800 Loss:tensor(0.0841, grad_fn=<DivBackward0>)\n",
            "Epoch:801 Loss:tensor(0.0735, grad_fn=<DivBackward0>)\n",
            "Epoch:802 Loss:tensor(0.0762, grad_fn=<DivBackward0>)\n",
            "Epoch:803 Loss:tensor(0.0775, grad_fn=<DivBackward0>)\n",
            "Epoch:804 Loss:tensor(0.0822, grad_fn=<DivBackward0>)\n",
            "Epoch:805 Loss:tensor(0.0808, grad_fn=<DivBackward0>)\n",
            "Epoch:806 Loss:tensor(0.0808, grad_fn=<DivBackward0>)\n",
            "Epoch:807 Loss:tensor(0.1110, grad_fn=<DivBackward0>)\n",
            "Epoch:808 Loss:tensor(0.0763, grad_fn=<DivBackward0>)\n",
            "Epoch:809 Loss:tensor(0.0699, grad_fn=<DivBackward0>)\n",
            "Epoch:810 Loss:tensor(0.1047, grad_fn=<DivBackward0>)\n",
            "Epoch:811 Loss:tensor(0.1177, grad_fn=<DivBackward0>)\n",
            "Epoch:812 Loss:tensor(0.1180, grad_fn=<DivBackward0>)\n",
            "Epoch:813 Loss:tensor(0.0863, grad_fn=<DivBackward0>)\n",
            "Epoch:814 Loss:tensor(0.3603, grad_fn=<DivBackward0>)\n",
            "Epoch:815 Loss:tensor(0.2276, grad_fn=<DivBackward0>)\n",
            "Epoch:816 Loss:tensor(0.1014, grad_fn=<DivBackward0>)\n",
            "Epoch:817 Loss:tensor(0.0849, grad_fn=<DivBackward0>)\n",
            "Epoch:818 Loss:tensor(0.0769, grad_fn=<DivBackward0>)\n",
            "Epoch:819 Loss:tensor(0.0670, grad_fn=<DivBackward0>)\n",
            "Epoch:820 Loss:tensor(0.0817, grad_fn=<DivBackward0>)\n",
            "Epoch:821 Loss:tensor(0.0685, grad_fn=<DivBackward0>)\n",
            "Epoch:822 Loss:tensor(0.0742, grad_fn=<DivBackward0>)\n",
            "Epoch:823 Loss:tensor(0.0760, grad_fn=<DivBackward0>)\n",
            "Epoch:824 Loss:tensor(0.1235, grad_fn=<DivBackward0>)\n",
            "Epoch:825 Loss:tensor(0.1206, grad_fn=<DivBackward0>)\n",
            "Epoch:826 Loss:tensor(0.0744, grad_fn=<DivBackward0>)\n",
            "Epoch:827 Loss:tensor(0.0857, grad_fn=<DivBackward0>)\n",
            "Epoch:828 Loss:tensor(0.0981, grad_fn=<DivBackward0>)\n",
            "Epoch:829 Loss:tensor(0.0740, grad_fn=<DivBackward0>)\n",
            "Epoch:830 Loss:tensor(0.0694, grad_fn=<DivBackward0>)\n",
            "Epoch:831 Loss:tensor(0.0788, grad_fn=<DivBackward0>)\n",
            "Epoch:832 Loss:tensor(0.0707, grad_fn=<DivBackward0>)\n",
            "Epoch:833 Loss:tensor(0.0701, grad_fn=<DivBackward0>)\n",
            "Epoch:834 Loss:tensor(0.0650, grad_fn=<DivBackward0>)\n",
            "Epoch:835 Loss:tensor(0.0646, grad_fn=<DivBackward0>)\n",
            "Epoch:836 Loss:tensor(0.0691, grad_fn=<DivBackward0>)\n",
            "Epoch:837 Loss:tensor(0.1249, grad_fn=<DivBackward0>)\n",
            "Epoch:838 Loss:tensor(0.0782, grad_fn=<DivBackward0>)\n",
            "Epoch:839 Loss:tensor(0.0796, grad_fn=<DivBackward0>)\n",
            "Epoch:840 Loss:tensor(0.0715, grad_fn=<DivBackward0>)\n",
            "Epoch:841 Loss:tensor(0.0696, grad_fn=<DivBackward0>)\n",
            "Epoch:842 Loss:tensor(0.0761, grad_fn=<DivBackward0>)\n",
            "Epoch:843 Loss:tensor(0.0700, grad_fn=<DivBackward0>)\n",
            "Epoch:844 Loss:tensor(0.0681, grad_fn=<DivBackward0>)\n",
            "Epoch:845 Loss:tensor(0.0685, grad_fn=<DivBackward0>)\n",
            "Epoch:846 Loss:tensor(0.0716, grad_fn=<DivBackward0>)\n",
            "Epoch:847 Loss:tensor(0.0692, grad_fn=<DivBackward0>)\n",
            "Epoch:848 Loss:tensor(0.0695, grad_fn=<DivBackward0>)\n",
            "Epoch:849 Loss:tensor(0.0708, grad_fn=<DivBackward0>)\n",
            "Epoch:850 Loss:tensor(0.0746, grad_fn=<DivBackward0>)\n",
            "Epoch:851 Loss:tensor(0.0700, grad_fn=<DivBackward0>)\n",
            "Epoch:852 Loss:tensor(0.0724, grad_fn=<DivBackward0>)\n",
            "Epoch:853 Loss:tensor(0.0695, grad_fn=<DivBackward0>)\n",
            "Epoch:854 Loss:tensor(0.0809, grad_fn=<DivBackward0>)\n",
            "Epoch:855 Loss:tensor(0.2673, grad_fn=<DivBackward0>)\n",
            "Epoch:856 Loss:tensor(0.2025, grad_fn=<DivBackward0>)\n",
            "Epoch:857 Loss:tensor(0.0926, grad_fn=<DivBackward0>)\n",
            "Epoch:858 Loss:tensor(0.0829, grad_fn=<DivBackward0>)\n",
            "Epoch:859 Loss:tensor(0.0775, grad_fn=<DivBackward0>)\n",
            "Epoch:860 Loss:tensor(0.0752, grad_fn=<DivBackward0>)\n",
            "Epoch:861 Loss:tensor(0.0720, grad_fn=<DivBackward0>)\n",
            "Epoch:862 Loss:tensor(0.0759, grad_fn=<DivBackward0>)\n",
            "Epoch:863 Loss:tensor(0.0705, grad_fn=<DivBackward0>)\n",
            "Epoch:864 Loss:tensor(0.0732, grad_fn=<DivBackward0>)\n",
            "Epoch:865 Loss:tensor(0.0675, grad_fn=<DivBackward0>)\n",
            "Epoch:866 Loss:tensor(0.0815, grad_fn=<DivBackward0>)\n",
            "Epoch:867 Loss:tensor(0.0686, grad_fn=<DivBackward0>)\n",
            "Epoch:868 Loss:tensor(0.0716, grad_fn=<DivBackward0>)\n",
            "Epoch:869 Loss:tensor(0.0797, grad_fn=<DivBackward0>)\n",
            "Epoch:870 Loss:tensor(0.0708, grad_fn=<DivBackward0>)\n",
            "Epoch:871 Loss:tensor(0.0723, grad_fn=<DivBackward0>)\n",
            "Epoch:872 Loss:tensor(0.0665, grad_fn=<DivBackward0>)\n",
            "Epoch:873 Loss:tensor(0.1065, grad_fn=<DivBackward0>)\n",
            "Epoch:874 Loss:tensor(0.0733, grad_fn=<DivBackward0>)\n",
            "Epoch:875 Loss:tensor(0.0828, grad_fn=<DivBackward0>)\n",
            "Epoch:876 Loss:tensor(0.0735, grad_fn=<DivBackward0>)\n",
            "Epoch:877 Loss:tensor(0.0749, grad_fn=<DivBackward0>)\n",
            "Epoch:878 Loss:tensor(0.0720, grad_fn=<DivBackward0>)\n",
            "Epoch:879 Loss:tensor(0.0709, grad_fn=<DivBackward0>)\n",
            "Epoch:880 Loss:tensor(0.0743, grad_fn=<DivBackward0>)\n",
            "Epoch:881 Loss:tensor(0.0692, grad_fn=<DivBackward0>)\n",
            "Epoch:882 Loss:tensor(0.0726, grad_fn=<DivBackward0>)\n",
            "Epoch:883 Loss:tensor(0.0652, grad_fn=<DivBackward0>)\n",
            "Epoch:884 Loss:tensor(0.0790, grad_fn=<DivBackward0>)\n",
            "Epoch:885 Loss:tensor(0.0769, grad_fn=<DivBackward0>)\n",
            "Epoch:886 Loss:tensor(0.0753, grad_fn=<DivBackward0>)\n",
            "Epoch:887 Loss:tensor(0.0676, grad_fn=<DivBackward0>)\n",
            "Epoch:888 Loss:tensor(0.0698, grad_fn=<DivBackward0>)\n",
            "Epoch:889 Loss:tensor(0.0735, grad_fn=<DivBackward0>)\n",
            "Epoch:890 Loss:tensor(0.1290, grad_fn=<DivBackward0>)\n",
            "Epoch:891 Loss:tensor(0.0835, grad_fn=<DivBackward0>)\n",
            "Epoch:892 Loss:tensor(0.0825, grad_fn=<DivBackward0>)\n",
            "Epoch:893 Loss:tensor(0.0685, grad_fn=<DivBackward0>)\n",
            "Epoch:894 Loss:tensor(0.0981, grad_fn=<DivBackward0>)\n",
            "Epoch:895 Loss:tensor(0.0746, grad_fn=<DivBackward0>)\n",
            "Epoch:896 Loss:tensor(0.0684, grad_fn=<DivBackward0>)\n",
            "Epoch:897 Loss:tensor(0.0635, grad_fn=<DivBackward0>)\n",
            "Epoch:898 Loss:tensor(0.4062, grad_fn=<DivBackward0>)\n",
            "Epoch:899 Loss:tensor(0.1122, grad_fn=<DivBackward0>)\n",
            "Epoch:900 Loss:tensor(0.0880, grad_fn=<DivBackward0>)\n",
            "Epoch:901 Loss:tensor(0.0771, grad_fn=<DivBackward0>)\n",
            "Epoch:902 Loss:tensor(0.1493, grad_fn=<DivBackward0>)\n",
            "Epoch:903 Loss:tensor(0.1228, grad_fn=<DivBackward0>)\n",
            "Epoch:904 Loss:tensor(0.1053, grad_fn=<DivBackward0>)\n",
            "Epoch:905 Loss:tensor(0.0688, grad_fn=<DivBackward0>)\n",
            "Epoch:906 Loss:tensor(0.1102, grad_fn=<DivBackward0>)\n",
            "Epoch:907 Loss:tensor(0.0707, grad_fn=<DivBackward0>)\n",
            "Epoch:908 Loss:tensor(0.0700, grad_fn=<DivBackward0>)\n",
            "Epoch:909 Loss:tensor(0.0688, grad_fn=<DivBackward0>)\n",
            "Epoch:910 Loss:tensor(0.0645, grad_fn=<DivBackward0>)\n",
            "Epoch:911 Loss:tensor(0.0703, grad_fn=<DivBackward0>)\n",
            "Epoch:912 Loss:tensor(0.0721, grad_fn=<DivBackward0>)\n",
            "Epoch:913 Loss:tensor(0.0677, grad_fn=<DivBackward0>)\n",
            "Epoch:914 Loss:tensor(0.0737, grad_fn=<DivBackward0>)\n",
            "Epoch:915 Loss:tensor(0.1145, grad_fn=<DivBackward0>)\n",
            "Epoch:916 Loss:tensor(0.0591, grad_fn=<DivBackward0>)\n",
            "Epoch:917 Loss:tensor(0.1059, grad_fn=<DivBackward0>)\n",
            "Epoch:918 Loss:tensor(0.0724, grad_fn=<DivBackward0>)\n",
            "Epoch:919 Loss:tensor(0.0813, grad_fn=<DivBackward0>)\n",
            "Epoch:920 Loss:tensor(0.0665, grad_fn=<DivBackward0>)\n",
            "Epoch:921 Loss:tensor(0.0654, grad_fn=<DivBackward0>)\n",
            "Epoch:922 Loss:tensor(0.0625, grad_fn=<DivBackward0>)\n",
            "Epoch:923 Loss:tensor(0.0708, grad_fn=<DivBackward0>)\n",
            "Epoch:924 Loss:tensor(0.0683, grad_fn=<DivBackward0>)\n",
            "Epoch:925 Loss:tensor(0.0675, grad_fn=<DivBackward0>)\n",
            "Epoch:926 Loss:tensor(0.0762, grad_fn=<DivBackward0>)\n",
            "Epoch:927 Loss:tensor(0.1542, grad_fn=<DivBackward0>)\n",
            "Epoch:928 Loss:tensor(0.0649, grad_fn=<DivBackward0>)\n",
            "Epoch:929 Loss:tensor(0.0730, grad_fn=<DivBackward0>)\n",
            "Epoch:930 Loss:tensor(0.0754, grad_fn=<DivBackward0>)\n",
            "Epoch:931 Loss:tensor(0.0691, grad_fn=<DivBackward0>)\n",
            "Epoch:932 Loss:tensor(0.0912, grad_fn=<DivBackward0>)\n",
            "Epoch:933 Loss:tensor(0.1187, grad_fn=<DivBackward0>)\n",
            "Epoch:934 Loss:tensor(0.1915, grad_fn=<DivBackward0>)\n",
            "Epoch:935 Loss:tensor(0.1216, grad_fn=<DivBackward0>)\n",
            "Epoch:936 Loss:tensor(0.2408, grad_fn=<DivBackward0>)\n",
            "Epoch:937 Loss:tensor(0.1771, grad_fn=<DivBackward0>)\n",
            "Epoch:938 Loss:tensor(0.0717, grad_fn=<DivBackward0>)\n",
            "Epoch:939 Loss:tensor(0.0999, grad_fn=<DivBackward0>)\n",
            "Epoch:940 Loss:tensor(0.0680, grad_fn=<DivBackward0>)\n",
            "Epoch:941 Loss:tensor(0.0633, grad_fn=<DivBackward0>)\n",
            "Epoch:942 Loss:tensor(0.0597, grad_fn=<DivBackward0>)\n",
            "Epoch:943 Loss:tensor(0.0575, grad_fn=<DivBackward0>)\n",
            "Epoch:944 Loss:tensor(0.0653, grad_fn=<DivBackward0>)\n",
            "Epoch:945 Loss:tensor(0.0598, grad_fn=<DivBackward0>)\n",
            "Epoch:946 Loss:tensor(0.0586, grad_fn=<DivBackward0>)\n",
            "Epoch:947 Loss:tensor(0.0564, grad_fn=<DivBackward0>)\n",
            "Epoch:948 Loss:tensor(0.0630, grad_fn=<DivBackward0>)\n",
            "Epoch:949 Loss:tensor(0.0609, grad_fn=<DivBackward0>)\n",
            "Epoch:950 Loss:tensor(0.0614, grad_fn=<DivBackward0>)\n",
            "Epoch:951 Loss:tensor(0.0600, grad_fn=<DivBackward0>)\n",
            "Epoch:952 Loss:tensor(0.0591, grad_fn=<DivBackward0>)\n",
            "Epoch:953 Loss:tensor(0.0675, grad_fn=<DivBackward0>)\n",
            "Epoch:954 Loss:tensor(0.0663, grad_fn=<DivBackward0>)\n",
            "Epoch:955 Loss:tensor(0.0691, grad_fn=<DivBackward0>)\n",
            "Epoch:956 Loss:tensor(0.0769, grad_fn=<DivBackward0>)\n",
            "Epoch:957 Loss:tensor(0.0636, grad_fn=<DivBackward0>)\n",
            "Epoch:958 Loss:tensor(0.0584, grad_fn=<DivBackward0>)\n",
            "Epoch:959 Loss:tensor(0.0607, grad_fn=<DivBackward0>)\n",
            "Epoch:960 Loss:tensor(0.0628, grad_fn=<DivBackward0>)\n",
            "Epoch:961 Loss:tensor(0.1087, grad_fn=<DivBackward0>)\n",
            "Epoch:962 Loss:tensor(0.1974, grad_fn=<DivBackward0>)\n",
            "Epoch:963 Loss:tensor(0.1143, grad_fn=<DivBackward0>)\n",
            "Epoch:964 Loss:tensor(0.0678, grad_fn=<DivBackward0>)\n",
            "Epoch:965 Loss:tensor(0.0717, grad_fn=<DivBackward0>)\n",
            "Epoch:966 Loss:tensor(0.0836, grad_fn=<DivBackward0>)\n",
            "Epoch:967 Loss:tensor(0.0728, grad_fn=<DivBackward0>)\n",
            "Epoch:968 Loss:tensor(0.0844, grad_fn=<DivBackward0>)\n",
            "Epoch:969 Loss:tensor(0.0783, grad_fn=<DivBackward0>)\n",
            "Epoch:970 Loss:tensor(0.0649, grad_fn=<DivBackward0>)\n",
            "Epoch:971 Loss:tensor(0.0610, grad_fn=<DivBackward0>)\n",
            "Epoch:972 Loss:tensor(0.0587, grad_fn=<DivBackward0>)\n",
            "Epoch:973 Loss:tensor(0.0591, grad_fn=<DivBackward0>)\n",
            "Epoch:974 Loss:tensor(0.0552, grad_fn=<DivBackward0>)\n",
            "Epoch:975 Loss:tensor(0.0597, grad_fn=<DivBackward0>)\n",
            "Epoch:976 Loss:tensor(0.0576, grad_fn=<DivBackward0>)\n",
            "Epoch:977 Loss:tensor(0.0574, grad_fn=<DivBackward0>)\n",
            "Epoch:978 Loss:tensor(0.0556, grad_fn=<DivBackward0>)\n",
            "Epoch:979 Loss:tensor(0.0667, grad_fn=<DivBackward0>)\n",
            "Epoch:980 Loss:tensor(0.0670, grad_fn=<DivBackward0>)\n",
            "Epoch:981 Loss:tensor(0.0667, grad_fn=<DivBackward0>)\n",
            "Epoch:982 Loss:tensor(0.0686, grad_fn=<DivBackward0>)\n",
            "Epoch:983 Loss:tensor(0.0672, grad_fn=<DivBackward0>)\n",
            "Epoch:984 Loss:tensor(0.0545, grad_fn=<DivBackward0>)\n",
            "Epoch:985 Loss:tensor(0.2981, grad_fn=<DivBackward0>)\n",
            "Epoch:986 Loss:tensor(0.0837, grad_fn=<DivBackward0>)\n",
            "Epoch:987 Loss:tensor(0.0597, grad_fn=<DivBackward0>)\n",
            "Epoch:988 Loss:tensor(0.0553, grad_fn=<DivBackward0>)\n",
            "Epoch:989 Loss:tensor(0.0742, grad_fn=<DivBackward0>)\n",
            "Epoch:990 Loss:tensor(0.0651, grad_fn=<DivBackward0>)\n",
            "Epoch:991 Loss:tensor(0.0546, grad_fn=<DivBackward0>)\n",
            "Epoch:992 Loss:tensor(0.0559, grad_fn=<DivBackward0>)\n",
            "Epoch:993 Loss:tensor(0.0567, grad_fn=<DivBackward0>)\n",
            "Epoch:994 Loss:tensor(0.2184, grad_fn=<DivBackward0>)\n",
            "Epoch:995 Loss:tensor(0.1043, grad_fn=<DivBackward0>)\n",
            "Epoch:996 Loss:tensor(0.0683, grad_fn=<DivBackward0>)\n",
            "Epoch:997 Loss:tensor(0.0547, grad_fn=<DivBackward0>)\n",
            "Epoch:998 Loss:tensor(0.0662, grad_fn=<DivBackward0>)\n",
            "Epoch:999 Loss:tensor(0.0559, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yQr5nZpwvb0"
      },
      "source": [
        "#testing\n",
        "test_set=DataLoader(dataset=test_set,batch_size=4,shuffle=True)\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqFQ6oUOKJg3",
        "outputId": "5eee88d6-457f-4e30-dd37-3aedc426ef3b"
      },
      "source": [
        "with torch.no_grad():\n",
        "  n_correct=0\n",
        "  n_samples=0\n",
        "\n",
        "  for i,(inputs,labels) in enumerate(test_set):\n",
        "      outputs=n(inputs)\n",
        "      labels=labels-1\n",
        "      \n",
        "      _,predictions=torch.max(outputs,1)\n",
        "      n_samples+=labels.shape[0]\n",
        "      print(predictions,labels)\n",
        "      n_correct+=(predictions==labels).sum().item()\n",
        "  acc=100.0*n_correct/n_samples\n",
        "  print(\"Accuracy:\",acc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 1, 2]) tensor([0, 0, 1, 2])\n",
            "tensor([1, 0, 1, 1]) tensor([1, 0, 1, 1])\n",
            "tensor([1, 1, 0, 0]) tensor([1, 1, 0, 0])\n",
            "tensor([1, 2, 2, 2]) tensor([1, 2, 2, 2])\n",
            "tensor([0, 1, 0, 2]) tensor([0, 1, 0, 2])\n",
            "tensor([0, 1, 1, 1]) tensor([0, 1, 1, 1])\n",
            "tensor([0, 1, 1, 0]) tensor([0, 1, 0, 0])\n",
            "tensor([0, 1]) tensor([0, 2])\n",
            "Accuracy: 93.33333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JsRt2dKLNob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}